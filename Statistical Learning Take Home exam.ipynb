{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Statistical Learning Take Home exam.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNB4c8AWU6CRvmKROeYpgMw"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"-rwYf2rYdwm5"},"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib as mpl\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.metrics import confusion_matrix\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn.neighbors import KNeighborsClassifier\r\n","from sklearn.ensemble import ExtraTreesClassifier\r\n","from sklearn.model_selection import RepeatedStratifiedKFold\r\n","from sklearn.model_selection import GridSearchCV\r\n","from IPython.display import display, HTML"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"KVffw9gEeYVo","outputId":"9ccbd068-1706-4c69-cc5e-e8bdc5ca129b"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive',force_remount=True)\r\n","\r\n","path_train = '/content/drive/My Drive/Take home exam statistic learning/zip.train.txt'\r\n","path_test = '/content/drive/My Drive/Take home exam statistic learning/zip.test.txt'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aCs2JXIOewMe"},"source":["df_train  = pd.read_csv(path_train, sep=\" \", header=None)\r\n","df_test = pd.read_csv(path_test, sep=\" \", header=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n8vOYsVjxbzs"},"source":["df_train = df_train.drop(columns = 257)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m71tQlshcvL1"},"source":["print(df_train.min())\r\n","print(df_train.max())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BAZ8Q2jZfULe"},"source":["X_train = df_train[(df_train[0] == 2.0) | (df_train[0] == 3.0) | (df_train[0] == 5.0)]\r\n","X_test = df_test[(df_test[0] == 2.0) | (df_test[0] == 3.0) | (df_test[0] == 5.0)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3H_ZQoooWOG"},"source":["y_train = X_train[0]\r\n","X_train = X_train.drop(columns = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hU6HpNAzox1Z"},"source":["y_test = X_test[0]\r\n","X_test = X_test.drop(columns = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STzDE-rbyV5L"},"source":["Performance measure"]},{"cell_type":"code","metadata":{"id":"Ee-mTpDLyVLt"},"source":["def classification_multi_class_report(y_test, model_predictions):\r\n","    report = classification_report(y_test, model_predictions, output_dict=True)\r\n","    display(pd.DataFrame(report).transpose().round(4))\r\n","\r\n","def confusion_multi_class_report(y_test, model_predictions):\r\n","    labels= [2,3,5]\r\n","    report = confusion_matrix(y_test, model_predictions, labels=labels)\r\n","    display(pd.DataFrame(report, index=labels, columns=labels).round(4))\r\n","\r\n","def auc_value(y_test , y_test_predicted):\r\n","  fpr_test, tpr_test, thresholds_test = metrics.roc_curve(y_test , y_test_predicted , pos_label=1)\r\n","  auc_value_test = metrics.auc(fpr_test, tpr_test)\r\n","  print(\"AUC value: \" + str(auc_value_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpdEs3Su3rfd"},"source":["def print_results(y, y_predicted):\r\n","  print('Classification report:')\r\n","  classification_multi_class_report(y, y_predicted)\r\n","  print('Confusion matrix:')\r\n","  confusion_multi_class_report(y, y_predicted)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCKuV4oyr2IU"},"source":["def print_results_test_train(y_test, y_train, y_test_predicted, y_train_predicted):\r\n","  print(\"Test results:\")\r\n","  print_results(y_test, y_test_predicted)\r\n","  print(\"Train results:\")\r\n","  print_results(y_train, y_train_predicted)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YgBT-VgLlglt"},"source":["LDA"]},{"cell_type":"code","metadata":{"id":"FfaLtkEK0sIk"},"source":["print(\"before hyper parameters tuning:\")\r\n","print_results_test_train(y_test, y_train, y_test_predicted, y_train_predicted)\r\n","print(LDA.get_params())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QkfOAeSM09RL"},"source":["print(\"after hyper parameters tuning:\")\r\n","print_results_test_train(y_test, y_train, y_test_predicted, y_train_predicted)\r\n","print(search.best_params_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZffYkFtzg8bJ","executionInfo":{"elapsed":436382,"status":"ok","timestamp":1613311526905,"user":{"displayName":"Anna Mosenzon","photoUrl":"","userId":"16011365326734362597"},"user_tz":-120},"outputId":"c2bd010a-df6f-4de8-fdce-0afa45130af7"},"source":["LDA = LinearDiscriminantAnalysis()\r\n","LDA.fit(X_train, y_train)\r\n","y_test_predicted = LDA.predict(X_test)\r\n","y_train_predicted = LDA.predict(X_train)\r\n","\r\n","print(\"before hyper parameters tuning:\")\r\n","print_results_test_train(y_test, y_train, y_test_predicted, y_train_predicted)\r\n","print(LDA.get_params())\r\n","\r\n","# hyper_param_tune:\r\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n","grid = dict()\r\n","grid['solver'] = ['svd', 'lsqr', 'eigen']\r\n","\r\n","arr1 = np.arange(0, 1, 0.01)\r\n","arr2 = np.array([None, 'auto'])\r\n","shrinkage_vals = np.concatenate((arr1, arr2))\r\n","grid['shrinkage'] = shrinkage_vals\r\n","\r\n","search = GridSearchCV(LDA, param_grid= grid, scoring='accuracy', cv=cv, n_jobs=-1)\r\n","search.fit(X_train, y_train)\r\n","y_test_predicted_hpt = search.predict(X_test)\r\n","y_train_predicted_hpt = search.predict(X_train)\r\n","\r\n","print(\"after hyper parameters tuning:\")\r\n","print_results_test_train(y_test, y_train, y_test_predicted_hpt, y_train_predicted_hpt)\r\n","print(search.best_params_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["before hyper parameters tuning:\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9684</td>\n","      <td>0.9293</td>\n","      <td>0.9485</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.8409</td>\n","      <td>0.8916</td>\n","      <td>0.8655</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.8987</td>\n","      <td>0.8875</td>\n","      <td>0.8931</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9046</td>\n","      <td>0.9046</td>\n","      <td>0.9046</td>\n","      <td>0.9046</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9027</td>\n","      <td>0.9028</td>\n","      <td>0.9023</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9067</td>\n","      <td>0.9046</td>\n","      <td>0.9053</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9684  0.9293    0.9485  198.0000\n","3                0.8409  0.8916    0.8655  166.0000\n","5                0.8987  0.8875    0.8931  160.0000\n","accuracy         0.9046  0.9046    0.9046    0.9046\n","macro avg        0.9027  0.9028    0.9023  524.0000\n","weighted avg     0.9067  0.9046    0.9053  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>184</td>\n","      <td>10</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>142</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  184   10    4\n","3    6  148   12\n","5    0   18  142"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>0.9863</td>\n","      <td>0.9836</td>\n","      <td>0.9849</td>\n","      <td>731.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>0.9612</td>\n","      <td>0.9787</td>\n","      <td>0.9699</td>\n","      <td>658.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>0.9835</td>\n","      <td>0.9658</td>\n","      <td>0.9746</td>\n","      <td>556.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9769</td>\n","      <td>0.9769</td>\n","      <td>0.9769</td>\n","      <td>0.9769</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9770</td>\n","      <td>0.9760</td>\n","      <td>0.9765</td>\n","      <td>1945.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9770</td>\n","      <td>0.9769</td>\n","      <td>0.9769</td>\n","      <td>1945.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score    support\n","2.0              0.9863  0.9836    0.9849   731.0000\n","3.0              0.9612  0.9787    0.9699   658.0000\n","5.0              0.9835  0.9658    0.9746   556.0000\n","accuracy         0.9769  0.9769    0.9769     0.9769\n","macro avg        0.9770  0.9760    0.9765  1945.0000\n","weighted avg     0.9770  0.9769    0.9769  1945.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>719</td>\n","      <td>10</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7</td>\n","      <td>644</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3</td>\n","      <td>16</td>\n","      <td>537</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  719   10    2\n","3    7  644    7\n","5    3   16  537"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}\n","after hyper parameters tuning:\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9684</td>\n","      <td>0.9293</td>\n","      <td>0.9485</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.8409</td>\n","      <td>0.8916</td>\n","      <td>0.8655</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.8987</td>\n","      <td>0.8875</td>\n","      <td>0.8931</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9046</td>\n","      <td>0.9046</td>\n","      <td>0.9046</td>\n","      <td>0.9046</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9027</td>\n","      <td>0.9028</td>\n","      <td>0.9023</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9067</td>\n","      <td>0.9046</td>\n","      <td>0.9053</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9684  0.9293    0.9485  198.0000\n","3                0.8409  0.8916    0.8655  166.0000\n","5                0.8987  0.8875    0.8931  160.0000\n","accuracy         0.9046  0.9046    0.9046    0.9046\n","macro avg        0.9027  0.9028    0.9023  524.0000\n","weighted avg     0.9067  0.9046    0.9053  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>184</td>\n","      <td>10</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>142</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  184   10    4\n","3    6  148   12\n","5    0   18  142"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>0.9849</td>\n","      <td>0.9836</td>\n","      <td>0.9843</td>\n","      <td>731.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>0.9598</td>\n","      <td>0.9787</td>\n","      <td>0.9691</td>\n","      <td>658.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>0.9835</td>\n","      <td>0.9622</td>\n","      <td>0.9727</td>\n","      <td>556.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9758</td>\n","      <td>0.9758</td>\n","      <td>0.9758</td>\n","      <td>0.9758</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9760</td>\n","      <td>0.9748</td>\n","      <td>0.9754</td>\n","      <td>1945.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9760</td>\n","      <td>0.9758</td>\n","      <td>0.9759</td>\n","      <td>1945.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score    support\n","2.0              0.9849  0.9836    0.9843   731.0000\n","3.0              0.9598  0.9787    0.9691   658.0000\n","5.0              0.9835  0.9622    0.9727   556.0000\n","accuracy         0.9758  0.9758    0.9758     0.9758\n","macro avg        0.9760  0.9748    0.9754  1945.0000\n","weighted avg     0.9760  0.9758    0.9759  1945.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>719</td>\n","      <td>10</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7</td>\n","      <td>644</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4</td>\n","      <td>17</td>\n","      <td>535</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  719   10    2\n","3    7  644    7\n","5    4   17  535"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{'shrinkage': 0.01, 'solver': 'lsqr'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CMkg9wrz6jWj"},"source":["Multi-class logistic regression:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"kyT-HN-3tg6K","executionInfo":{"elapsed":834580,"status":"ok","timestamp":1613316004120,"user":{"displayName":"Anna Mosenzon","photoUrl":"","userId":"16011365326734362597"},"user_tz":-120},"outputId":"beb120e9-ba13-4611-bb63-6a5bd6310f31"},"source":["LogReg = LogisticRegression(random_state=0, multi_class = 'multinomial')\r\n","LogReg.fit(X_train, y_train)\r\n","y_test_predicted = LogReg.predict(X_test)\r\n","y_train_predicted = LogReg.predict(X_train)\r\n","\r\n","print(\"before hyper parameters tuning:\")\r\n","print_results_test_train(y_test, y_train, y_test_predicted, y_train_predicted)\r\n","print(LogReg.get_params())\r\n","\r\n","# hyper_param_tune:\r\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n","\r\n","solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\r\n","penalty = ['l2', 'l1', 'elasticnet', 'none']\r\n","c_values = [100, 10, 1.0, 0.1, 0.01]\r\n","# define grid search\r\n","grid = dict(solver=solvers,penalty=penalty,C=c_values)\r\n","\r\n","search = GridSearchCV(LogReg, param_grid= grid, scoring='accuracy', cv=cv, n_jobs=-1)\r\n","search.fit(X_train, y_train)\r\n","y_test_predicted_hpt = search.predict(X_test)\r\n","y_train_predicted_hpt = search.predict(X_train)\r\n","\r\n","print(\"after hyper parameters tuning:\")\r\n","print_results_test_train(y_test, y_train, y_test_predicted_hpt, y_train_predicted_hpt)\r\n","print(search.best_params_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["before hyper parameters tuning:\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9689</td>\n","      <td>0.9444</td>\n","      <td>0.9565</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.8830</td>\n","      <td>0.9096</td>\n","      <td>0.8961</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9125</td>\n","      <td>0.9125</td>\n","      <td>0.9125</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9237</td>\n","      <td>0.9237</td>\n","      <td>0.9237</td>\n","      <td>0.9237</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9215</td>\n","      <td>0.9222</td>\n","      <td>0.9217</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9245</td>\n","      <td>0.9237</td>\n","      <td>0.9240</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9689  0.9444    0.9565  198.0000\n","3                0.8830  0.9096    0.8961  166.0000\n","5                0.9125  0.9125    0.9125  160.0000\n","accuracy         0.9237  0.9237    0.9237    0.9237\n","macro avg        0.9215  0.9222    0.9217  524.0000\n","weighted avg     0.9245  0.9237    0.9240  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>187</td>\n","      <td>7</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>151</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>13</td>\n","      <td>146</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  187    7    4\n","3    5  151   10\n","5    1   13  146"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1.0000</td>\n","      <td>1.0000</td>\n","      <td>1.0000</td>\n","      <td>731.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>1.0000</td>\n","      <td>0.9985</td>\n","      <td>0.9992</td>\n","      <td>658.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>0.9982</td>\n","      <td>1.0000</td>\n","      <td>0.9991</td>\n","      <td>556.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9994</td>\n","      <td>0.9995</td>\n","      <td>0.9994</td>\n","      <td>1945.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","      <td>1945.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score    support\n","2.0              1.0000  1.0000    1.0000   731.0000\n","3.0              1.0000  0.9985    0.9992   658.0000\n","5.0              0.9982  1.0000    0.9991   556.0000\n","accuracy         0.9995  0.9995    0.9995     0.9995\n","macro avg        0.9994  0.9995    0.9994  1945.0000\n","weighted avg     0.9995  0.9995    0.9995  1945.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>731</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>657</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>556</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  731    0    0\n","3    0  657    1\n","5    0    0  556"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'l2', 'random_state': 0, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n","after hyper parameters tuning:\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9689</td>\n","      <td>0.9444</td>\n","      <td>0.9565</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.8941</td>\n","      <td>0.9157</td>\n","      <td>0.9048</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9193</td>\n","      <td>0.9250</td>\n","      <td>0.9221</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9294</td>\n","      <td>0.9294</td>\n","      <td>0.9294</td>\n","      <td>0.9294</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9274</td>\n","      <td>0.9284</td>\n","      <td>0.9278</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9301</td>\n","      <td>0.9294</td>\n","      <td>0.9296</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9689  0.9444    0.9565  198.0000\n","3                0.8941  0.9157    0.9048  166.0000\n","5                0.9193  0.9250    0.9221  160.0000\n","accuracy         0.9294  0.9294    0.9294    0.9294\n","macro avg        0.9274  0.9284    0.9278  524.0000\n","weighted avg     0.9301  0.9294    0.9296  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>187</td>\n","      <td>7</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>152</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>148</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  187    7    4\n","3    5  152    9\n","5    1   11  148"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>0.9905</td>\n","      <td>0.9945</td>\n","      <td>0.9925</td>\n","      <td>731.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>0.9863</td>\n","      <td>0.9878</td>\n","      <td>0.9871</td>\n","      <td>658.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>0.9855</td>\n","      <td>0.9784</td>\n","      <td>0.9819</td>\n","      <td>556.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9877</td>\n","      <td>0.9877</td>\n","      <td>0.9877</td>\n","      <td>0.9877</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9874</td>\n","      <td>0.9869</td>\n","      <td>0.9872</td>\n","      <td>1945.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9877</td>\n","      <td>0.9877</td>\n","      <td>0.9877</td>\n","      <td>1945.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score    support\n","2.0              0.9905  0.9945    0.9925   731.0000\n","3.0              0.9863  0.9878    0.9871   658.0000\n","5.0              0.9855  0.9784    0.9819   556.0000\n","accuracy         0.9877  0.9877    0.9877     0.9877\n","macro avg        0.9874  0.9869    0.9872  1945.0000\n","weighted avg     0.9877  0.9877    0.9877  1945.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>727</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>650</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>544</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  727    2    2\n","3    2  650    6\n","5    5    7  544"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9689</td>\n","      <td>0.9444</td>\n","      <td>0.9565</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.8830</td>\n","      <td>0.9096</td>\n","      <td>0.8961</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9125</td>\n","      <td>0.9125</td>\n","      <td>0.9125</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9237</td>\n","      <td>0.9237</td>\n","      <td>0.9237</td>\n","      <td>0.9237</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9215</td>\n","      <td>0.9222</td>\n","      <td>0.9217</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9245</td>\n","      <td>0.9237</td>\n","      <td>0.9240</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9689  0.9444    0.9565  198.0000\n","3                0.8830  0.9096    0.8961  166.0000\n","5                0.9125  0.9125    0.9125  160.0000\n","accuracy         0.9237  0.9237    0.9237    0.9237\n","macro avg        0.9215  0.9222    0.9217  524.0000\n","weighted avg     0.9245  0.9237    0.9240  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>187</td>\n","      <td>7</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>151</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>13</td>\n","      <td>146</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  187    7    4\n","3    5  151   10\n","5    1   13  146"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1.0000</td>\n","      <td>1.0000</td>\n","      <td>1.0000</td>\n","      <td>731.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>1.0000</td>\n","      <td>0.9985</td>\n","      <td>0.9992</td>\n","      <td>658.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>0.9982</td>\n","      <td>1.0000</td>\n","      <td>0.9991</td>\n","      <td>556.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9994</td>\n","      <td>0.9995</td>\n","      <td>0.9994</td>\n","      <td>1945.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","      <td>0.9995</td>\n","      <td>1945.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score    support\n","2.0              1.0000  1.0000    1.0000   731.0000\n","3.0              1.0000  0.9985    0.9992   658.0000\n","5.0              0.9982  1.0000    0.9991   556.0000\n","accuracy         0.9995  0.9995    0.9995     0.9995\n","macro avg        0.9994  0.9995    0.9994  1945.0000\n","weighted avg     0.9995  0.9995    0.9995  1945.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>731</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>657</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>556</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  731    0    0\n","3    0  657    1\n","5    0    0  556"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"VOUqdbzdXKrN"},"source":["K-nearest neighbors:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"aeB9_MT47jgS","executionInfo":{"elapsed":583955,"status":"ok","timestamp":1613377964839,"user":{"displayName":"Anna Mosenzon","photoUrl":"","userId":"16011365326734362597"},"user_tz":-120},"outputId":"bc711b4c-3da2-45fc-ad7b-41de17626f25"},"source":["print(\"before hyper parameters tuning:\")\r\n","for k in [1,5,10,20]:\r\n","  KNN = KNeighborsClassifier(n_neighbors=k)\r\n","  KNN.fit(X_train, y_train)\r\n","  y_test_predicted = KNN.predict(X_test)\r\n","  y_train_predicted = KNN.predict(X_train)\r\n","\r\n","  print('k = ' + str(k))\r\n","  print_results_test_train(y_test, y_train, y_test_predicted, y_train_predicted)\r\n","\r\n","print(KNN.get_params())\r\n","\r\n","# hyper_param_tune:\r\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n","KNN = KNeighborsClassifier()\r\n","n_neighbors = range(1, 21)\r\n","weights = ['uniform', 'distance']\r\n","metric = ['euclidean', 'manhattan', 'minkowski']\r\n","\r\n","# define grid search\r\n","grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\r\n","\r\n","search = GridSearchCV(KNN, param_grid= grid, scoring='accuracy', cv=cv, n_jobs=-1)\r\n","search.fit(X_train, y_train)\r\n","y_test_predicted_hpt = search.predict(X_test)\r\n","y_train_predicted_hpt = search.predict(X_train)\r\n","\r\n","print(\"after hyper parameters tuning:\")\r\n","print_results_test_train(y_test, y_train, y_test_predicted_hpt, y_train_predicted_hpt)\r\n","print(search.best_params_)\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["before hyper parameters tuning:\n","k = 1\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9746</td>\n","      <td>0.9697</td>\n","      <td>0.9722</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.9394</td>\n","      <td>0.9337</td>\n","      <td>0.9366</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9444</td>\n","      <td>0.9562</td>\n","      <td>0.9503</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9542</td>\n","      <td>0.9542</td>\n","      <td>0.9542</td>\n","      <td>0.9542</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9528</td>\n","      <td>0.9532</td>\n","      <td>0.9530</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9542</td>\n","      <td>0.9542</td>\n","      <td>0.9542</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9746  0.9697    0.9722  198.0000\n","3                0.9394  0.9337    0.9366  166.0000\n","5                0.9444  0.9562    0.9503  160.0000\n","accuracy         0.9542  0.9542    0.9542    0.9542\n","macro avg        0.9528  0.9532    0.9530  524.0000\n","weighted avg     0.9542  0.9542    0.9542  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>192</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>155</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>153</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  192    5    1\n","3    3  155    8\n","5    2    5  153"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>731.0</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>658.0</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>556.0</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score  support\n","2.0                 1.0     1.0       1.0    731.0\n","3.0                 1.0     1.0       1.0    658.0\n","5.0                 1.0     1.0       1.0    556.0\n","accuracy            1.0     1.0       1.0      1.0\n","macro avg           1.0     1.0       1.0   1945.0\n","weighted avg        1.0     1.0       1.0   1945.0"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>731</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>658</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>556</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  731    0    0\n","3    0  658    0\n","5    0    0  556"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["k = 5\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9745</td>\n","      <td>0.9646</td>\n","      <td>0.9695</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.9281</td>\n","      <td>0.9337</td>\n","      <td>0.9309</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9503</td>\n","      <td>0.9562</td>\n","      <td>0.9533</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9523</td>\n","      <td>0.9523</td>\n","      <td>0.9523</td>\n","      <td>0.9523</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9510</td>\n","      <td>0.9515</td>\n","      <td>0.9512</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9524</td>\n","      <td>0.9523</td>\n","      <td>0.9523</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9745  0.9646    0.9695  198.0000\n","3                0.9281  0.9337    0.9309  166.0000\n","5                0.9503  0.9562    0.9533  160.0000\n","accuracy         0.9523  0.9523    0.9523    0.9523\n","macro avg        0.9510  0.9515    0.9512  524.0000\n","weighted avg     0.9524  0.9523    0.9523  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>191</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>155</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>153</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  191    6    1\n","3    4  155    7\n","5    1    6  153"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>0.9905</td>\n","      <td>0.9932</td>\n","      <td>0.9918</td>\n","      <td>731.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>0.9849</td>\n","      <td>0.9909</td>\n","      <td>0.9879</td>\n","      <td>658.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>0.9945</td>\n","      <td>0.9838</td>\n","      <td>0.9892</td>\n","      <td>556.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9897</td>\n","      <td>0.9897</td>\n","      <td>0.9897</td>\n","      <td>0.9897</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9900</td>\n","      <td>0.9893</td>\n","      <td>0.9896</td>\n","      <td>1945.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9897</td>\n","      <td>0.9897</td>\n","      <td>0.9897</td>\n","      <td>1945.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score    support\n","2.0              0.9905  0.9932    0.9918   731.0000\n","3.0              0.9849  0.9909    0.9879   658.0000\n","5.0              0.9945  0.9838    0.9892   556.0000\n","accuracy         0.9897  0.9897    0.9897     0.9897\n","macro avg        0.9900  0.9893    0.9896  1945.0000\n","weighted avg     0.9897  0.9897    0.9897  1945.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>726</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>652</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>547</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  726    5    0\n","3    3  652    3\n","5    4    5  547"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["k = 10\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9792</td>\n","      <td>0.9495</td>\n","      <td>0.9641</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.9107</td>\n","      <td>0.9217</td>\n","      <td>0.9162</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9329</td>\n","      <td>0.9562</td>\n","      <td>0.9444</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9427</td>\n","      <td>0.9427</td>\n","      <td>0.9427</td>\n","      <td>0.9427</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9409</td>\n","      <td>0.9425</td>\n","      <td>0.9416</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9434</td>\n","      <td>0.9427</td>\n","      <td>0.9429</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9792  0.9495    0.9641  198.0000\n","3                0.9107  0.9217    0.9162  166.0000\n","5                0.9329  0.9562    0.9444  160.0000\n","accuracy         0.9427  0.9427    0.9427    0.9427\n","macro avg        0.9409  0.9425    0.9416  524.0000\n","weighted avg     0.9434  0.9427    0.9429  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>188</td>\n","      <td>9</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>153</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>153</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  188    9    1\n","3    3  153   10\n","5    1    6  153"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>0.9864</td>\n","      <td>0.9904</td>\n","      <td>0.9884</td>\n","      <td>731.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>0.9731</td>\n","      <td>0.9878</td>\n","      <td>0.9804</td>\n","      <td>658.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>0.9926</td>\n","      <td>0.9694</td>\n","      <td>0.9809</td>\n","      <td>556.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9835</td>\n","      <td>0.9835</td>\n","      <td>0.9835</td>\n","      <td>0.9835</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9840</td>\n","      <td>0.9826</td>\n","      <td>0.9832</td>\n","      <td>1945.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9837</td>\n","      <td>0.9835</td>\n","      <td>0.9835</td>\n","      <td>1945.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score    support\n","2.0              0.9864  0.9904    0.9884   731.0000\n","3.0              0.9731  0.9878    0.9804   658.0000\n","5.0              0.9926  0.9694    0.9809   556.0000\n","accuracy         0.9835  0.9835    0.9835     0.9835\n","macro avg        0.9840  0.9826    0.9832  1945.0000\n","weighted avg     0.9837  0.9835    0.9835  1945.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>724</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>650</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>11</td>\n","      <td>539</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  724    7    0\n","3    4  650    4\n","5    6   11  539"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["k = 20\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9737</td>\n","      <td>0.9343</td>\n","      <td>0.9536</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.8908</td>\n","      <td>0.9337</td>\n","      <td>0.9118</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9375</td>\n","      <td>0.9375</td>\n","      <td>0.9375</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9351</td>\n","      <td>0.9351</td>\n","      <td>0.9351</td>\n","      <td>0.9351</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9340</td>\n","      <td>0.9352</td>\n","      <td>0.9343</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9364</td>\n","      <td>0.9351</td>\n","      <td>0.9354</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9737  0.9343    0.9536  198.0000\n","3                0.8908  0.9337    0.9118  166.0000\n","5                0.9375  0.9375    0.9375  160.0000\n","accuracy         0.9351  0.9351    0.9351    0.9351\n","macro avg        0.9340  0.9352    0.9343  524.0000\n","weighted avg     0.9364  0.9351    0.9354  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>185</td>\n","      <td>11</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>155</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>150</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  185   11    2\n","3    3  155    8\n","5    2    8  150"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>0.9836</td>\n","      <td>0.9850</td>\n","      <td>0.9843</td>\n","      <td>731.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>0.9686</td>\n","      <td>0.9848</td>\n","      <td>0.9766</td>\n","      <td>658.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>0.9890</td>\n","      <td>0.9676</td>\n","      <td>0.9782</td>\n","      <td>556.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9799</td>\n","      <td>0.9799</td>\n","      <td>0.9799</td>\n","      <td>0.9799</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9804</td>\n","      <td>0.9791</td>\n","      <td>0.9797</td>\n","      <td>1945.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9801</td>\n","      <td>0.9799</td>\n","      <td>0.9800</td>\n","      <td>1945.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score    support\n","2.0              0.9836  0.9850    0.9843   731.0000\n","3.0              0.9686  0.9848    0.9766   658.0000\n","5.0              0.9890  0.9676    0.9782   556.0000\n","accuracy         0.9799  0.9799    0.9799     0.9799\n","macro avg        0.9804  0.9791    0.9797  1945.0000\n","weighted avg     0.9801  0.9799    0.9800  1945.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>720</td>\n","      <td>11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>648</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>8</td>\n","      <td>10</td>\n","      <td>538</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  720   11    0\n","3    4  648    6\n","5    8   10  538"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 20, 'p': 2, 'weights': 'uniform'}\n","after hyper parameters tuning:\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9746</td>\n","      <td>0.9697</td>\n","      <td>0.9722</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.9390</td>\n","      <td>0.9277</td>\n","      <td>0.9333</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9387</td>\n","      <td>0.9562</td>\n","      <td>0.9474</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9523</td>\n","      <td>0.9523</td>\n","      <td>0.9523</td>\n","      <td>0.9523</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9508</td>\n","      <td>0.9512</td>\n","      <td>0.9510</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9524</td>\n","      <td>0.9523</td>\n","      <td>0.9523</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9746  0.9697    0.9722  198.0000\n","3                0.9390  0.9277    0.9333  166.0000\n","5                0.9387  0.9562    0.9474  160.0000\n","accuracy         0.9523  0.9523    0.9523    0.9523\n","macro avg        0.9508  0.9512    0.9510  524.0000\n","weighted avg     0.9524  0.9523    0.9523  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>192</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>154</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>153</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  192    5    1\n","3    3  154    9\n","5    2    5  153"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>731.0</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>658.0</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>556.0</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score  support\n","2.0                 1.0     1.0       1.0    731.0\n","3.0                 1.0     1.0       1.0    658.0\n","5.0                 1.0     1.0       1.0    556.0\n","accuracy            1.0     1.0       1.0      1.0\n","macro avg           1.0     1.0       1.0   1945.0\n","weighted avg        1.0     1.0       1.0   1945.0"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>731</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>658</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>556</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  731    0    0\n","3    0  658    0\n","5    0    0  556"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'distance'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ukyT7Qmx-JY7"},"source":["Random Forest:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":859},"id":"UX3Cw_N4-Kzx","outputId":"b1bda3d9-b05a-4932-aa05-ff4cf75dafb3"},"source":["RF = ExtraTreesClassifier()\r\n","RF.fit(X_train, y_train)\r\n","y_test_predicted = RF.predict(X_test)\r\n","y_train_predicted = RF.predict(X_train)\r\n","\r\n","print(\"before hyper parameters tuning:\")\r\n","print_results_test_train(y_test, y_train, y_test_predicted, y_train_predicted)\r\n","print('current params: ' + str(RF.get_params()))\r\n","\r\n","# hyper_param_tune:\r\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n","\r\n","# arr1 = np.arange(0, 1, 0.01)\r\n","arr1 = np.array(['log2','auto',None])\r\n","arr2 = np.array([None])\r\n","max_depth = np.concatenate(([80, 90, 100, 110], arr2))\r\n","max_features = np.concatenate(([2, 3],arr1))\r\n","\r\n","param_grid = {\r\n","    'bootstrap': [True, False],\r\n","    'max_depth': [80, 90, 100, 110],\r\n","    'max_features': [2, 3],\r\n","    'min_samples_leaf': [1, 2, 3, 4, 5],\r\n","    'min_samples_split': [2, 4 ,6, 8, 10, 12],\r\n","    'n_estimators': [100, 200, 300]\r\n","}\r\n","\r\n","search = GridSearchCV(RF, param_grid= param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\r\n","search.fit(X_train, y_train)\r\n","y_test_predicted_hpt = search.predict(X_test)\r\n","y_train_predicted_hpt = search.predict(X_train)\r\n","\r\n","print(\"after hyper parameters tuning:\")\r\n","print_results_test_train(y_test, y_train, y_test_predicted_hpt, y_train_predicted_hpt)\r\n","print('best params: ' + str(search.best_params_))\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["before hyper parameters tuning:\n","Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9742</td>\n","      <td>0.9545</td>\n","      <td>0.9643</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.9375</td>\n","      <td>0.9036</td>\n","      <td>0.9202</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9176</td>\n","      <td>0.9750</td>\n","      <td>0.9455</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9447</td>\n","      <td>0.9447</td>\n","      <td>0.9447</td>\n","      <td>0.9447</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9431</td>\n","      <td>0.9444</td>\n","      <td>0.9433</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9453</td>\n","      <td>0.9447</td>\n","      <td>0.9446</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9742  0.9545    0.9643  198.0000\n","3                0.9375  0.9036    0.9202  166.0000\n","5                0.9176  0.9750    0.9455  160.0000\n","accuracy         0.9447  0.9447    0.9447    0.9447\n","macro avg        0.9431  0.9444    0.9433  524.0000\n","weighted avg     0.9453  0.9447    0.9446  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>189</td>\n","      <td>6</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>150</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>156</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  189    6    3\n","3    5  150   11\n","5    0    4  156"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>731.0</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>658.0</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>556.0</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score  support\n","2.0                 1.0     1.0       1.0    731.0\n","3.0                 1.0     1.0       1.0    658.0\n","5.0                 1.0     1.0       1.0    556.0\n","accuracy            1.0     1.0       1.0      1.0\n","macro avg           1.0     1.0       1.0   1945.0\n","weighted avg        1.0     1.0       1.0   1945.0"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>731</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>658</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>556</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  731    0    0\n","3    0  658    0\n","5    0    0  556"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["current params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hHsOnkzVAFOH"},"source":["Neural Networks:"]},{"cell_type":"code","metadata":{"id":"y5Id-A4RJs_o"},"source":["from keras.models import Sequential\r\n","from keras.layers import Dense\r\n","from keras.wrappers.scikit_learn import KerasClassifier\r\n","from keras.utils import np_utils\r\n","from sklearn.model_selection import cross_val_score\r\n","from sklearn.model_selection import KFold\r\n","from sklearn.preprocessing import LabelEncoder\r\n","from sklearn.pipeline import Pipeline\r\n","\r\n","from keras.layers import Dropout\r\n","from keras.layers import Flatten\r\n","from keras.layers.convolutional import Conv2D\r\n","from keras.layers.convolutional import MaxPooling2D\r\n","from keras.utils import np_utils\r\n","from keras.callbacks import EarlyStopping"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VMVpKgAJy_j"},"source":["# encode class values as integers\r\n","encoder = LabelEncoder()\r\n","encoder.fit(y_train)\r\n","encoded_y = encoder.transform(y_train)\r\n","\r\n","# convert integers to dummy variables (i.e. one hot encoded)\r\n","dummy_y = np_utils.to_categorical(encoded_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cX9EXOEzKDdv"},"source":["# define baseline model\r\n","def baseline_model():\r\n","\t# create model\r\n","\tmodel = Sequential()\r\n","\tmodel.add(Dense(8, input_dim=256, activation='relu'))\r\n","\tmodel.add(Dense(3, activation='softmax'))\r\n","\t# Compile model\r\n","\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n","\treturn model\r\n","\r\n","\r\n","# # flatten 28*28 images to a 784 vector for each image\r\n","# num_pixels = X_train.shape[0] * X_train.shape[1]\r\n","# # X_train_nn = X_train.values.reshape((X_train.shape[0], num_pixels)).astype('float32')\r\n","# # X_test_nn = X_test.values.reshape((X_test.shape[0], num_pixels)).astype('float32')\r\n","\r\n","\r\n","# # normalize inputs from 0-255 to 0-1\r\n","# X_train = X_train / 255\r\n","# X_test = X_test / 255\r\n","# # one hot encode outputs\r\n","# y_train = np_utils.to_categorical(y_train)\r\n","# y_test = np_utils.to_categorical(y_test)\r\n","# num_classes = y_test.shape[1]\r\n","\r\n","\r\n","# def baseline_model():\r\n","# \t# create model\r\n","# \tmodel = Sequential()\r\n","# \tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\r\n","# \tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\r\n","# \t# Compile model\r\n","# \tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n","# \treturn model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":893},"id":"2DfqvnNzL_cI","executionInfo":{"elapsed":6455,"status":"ok","timestamp":1613302116365,"user":{"displayName":"Anna Mosenzon","photoUrl":"","userId":"16011365326734362597"},"user_tz":-120},"outputId":"66e8747f-45ac-4621-cc0d-fcd7cc3b1ba7"},"source":["NN = KerasClassifier(build_fn=baseline_model, epochs=10, batch_size=5, verbose=0)\r\n","NN.fit(X_train, y_train)\r\n","y_test_predicted = NN.predict(X_test)\r\n","y_train_predicted = NN.predict(X_train)\r\n","\r\n","print(\"Test results:\")\r\n","print_results(y_test, y_test_predicted)\r\n","print(\"Train results:\")\r\n","print_results(y_train, y_train_predicted)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.97</td>\n","      <td>0.93</td>\n","      <td>0.95</td>\n","      <td>198.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.92</td>\n","      <td>0.90</td>\n","      <td>0.91</td>\n","      <td>166.00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.89</td>\n","      <td>0.95</td>\n","      <td>0.92</td>\n","      <td>160.00</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","      <td>524.00</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","      <td>524.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score  support\n","2                  0.97    0.93      0.95   198.00\n","3                  0.92    0.90      0.91   166.00\n","5                  0.89    0.95      0.92   160.00\n","accuracy           0.93    0.93      0.93     0.93\n","macro avg          0.93    0.93      0.93   524.00\n","weighted avg       0.93    0.93      0.93   524.00"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>185</td>\n","      <td>6</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>150</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>152</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  185    6    7\n","3    4  150   12\n","5    1    7  152"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>731.0</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>658.0</td>\n","    </tr>\n","    <tr>\n","      <th>5.0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>556.0</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score  support\n","2.0                 1.0     1.0       1.0    731.0\n","3.0                 1.0     1.0       1.0    658.0\n","5.0                 1.0     1.0       1.0    556.0\n","accuracy            1.0     1.0       1.0      1.0\n","macro avg           1.0     1.0       1.0   1945.0\n","weighted avg        1.0     1.0       1.0   1945.0"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>731</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>656</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>556</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  731    0    0\n","3    0  656    2\n","5    0    0  556"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LG3TQzpWKzeR","executionInfo":{"elapsed":1173411,"status":"ok","timestamp":1613376534667,"user":{"displayName":"Anna Mosenzon","photoUrl":"","userId":"16011365326734362597"},"user_tz":-120},"outputId":"46bc60ab-c878-4dfb-e20e-99b53bbcb815"},"source":["# reshape to be [samples][width][height][channels]\r\n","X_train_nn = X_train\r\n","X_test_nn = X_test\r\n","\r\n","X_train_nn = X_train.values.reshape((X_train.shape[0], 16, 16, 1)).astype('float32')\r\n","X_test_nn = X_test.values.reshape((X_test.shape[0], 16, 16, 1)).astype('float32')\r\n","# normalize inputs from 0-255 to 0-1\r\n","X_train_nn = X_train_nn / 255\r\n","X_test_nn = X_test_nn / 255\r\n","# one hot encode outputs\r\n","y_train_nn = np_utils.to_categorical(y_train)\r\n","y_test_nn = np_utils.to_categorical(y_test)\r\n","num_classes = y_test_nn.shape[1]\r\n","\r\n","# define a simple CNN model\r\n","# def baseline_model():\r\n","# \t# create model\r\n","# \tmodel = Sequential()\r\n","# \tmodel.add(Conv2D(20, (3, 3), input_shape=(16, 16, 1), activation='relu'))\r\n","# \tmodel.add(MaxPooling2D())\r\n","# \tmodel.add(Dropout(0.2))\r\n","# \tmodel.add(Flatten())\r\n","# \tmodel.add(Dense(128, activation='relu'))\r\n","# \tmodel.add(Dense(num_classes, activation='softmax'))\r\n","# \t# Compile model\r\n","# \tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n","# \treturn model\r\n","\r\n","# define cnn model\r\n","def define_model():\r\n","\tmodel = Sequential()\r\n","\tmodel.add(Conv2D(20, (3, 3), activation='relu', input_shape=(16, 16, 1)))\r\n","\tmodel.add(Conv2D(20, (3, 3), activation='relu'))\r\n","\tmodel.add(MaxPooling2D((2, 2)))\r\n","\tmodel.add(Conv2D(64, (3, 3), activation='relu'))\r\n","\tmodel.add(Conv2D(64, (3, 3), activation='relu'))\r\n","\tmodel.add(MaxPooling2D((2, 2)))\r\n","\tmodel.add(Flatten())\r\n","\tmodel.add(Dense(128, activation='relu'))\r\n","\tmodel.add(Dense(num_classes, activation='softmax'))\r\n","\t# compile model\r\n","\topt = SGD(lr=0.0001, momentum=0.9)\r\n","\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\r\n","\treturn model\r\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\r\n","# build the model\r\n","NN = baseline_model()\r\n","# Fit the model\r\n","NN.fit(X_train_nn, y_train_nn, validation_data=(X_test_nn, y_test_nn), epochs=1000, batch_size=8)\r\n","scores = NN.evaluate(X_test_nn, y_test_nn, verbose=0)\r\n","print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/1000\n","244/244 [==============================] - 2s 5ms/step - loss: 1.2953 - accuracy: 0.3623 - val_loss: 1.0560 - val_accuracy: 0.3168\n","Epoch 2/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.9408 - accuracy: 0.5848 - val_loss: 0.4688 - val_accuracy: 0.8664\n","Epoch 3/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.3206 - accuracy: 0.9210 - val_loss: 0.2882 - val_accuracy: 0.9046\n","Epoch 4/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.1988 - accuracy: 0.9396 - val_loss: 0.2510 - val_accuracy: 0.9179\n","Epoch 5/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9411 - val_loss: 0.2357 - val_accuracy: 0.9275\n","Epoch 6/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.1344 - accuracy: 0.9589 - val_loss: 0.2280 - val_accuracy: 0.9160\n","Epoch 7/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9604 - val_loss: 0.2063 - val_accuracy: 0.9256\n","Epoch 8/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9645 - val_loss: 0.2120 - val_accuracy: 0.9179\n","Epoch 9/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9651 - val_loss: 0.2073 - val_accuracy: 0.9294\n","Epoch 10/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0817 - accuracy: 0.9715 - val_loss: 0.1968 - val_accuracy: 0.9294\n","Epoch 11/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.9595 - val_loss: 0.1942 - val_accuracy: 0.9275\n","Epoch 12/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9760 - val_loss: 0.2081 - val_accuracy: 0.9351\n","Epoch 13/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0724 - accuracy: 0.9758 - val_loss: 0.1948 - val_accuracy: 0.9351\n","Epoch 14/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0566 - accuracy: 0.9830 - val_loss: 0.1763 - val_accuracy: 0.9351\n","Epoch 15/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0683 - accuracy: 0.9768 - val_loss: 0.1898 - val_accuracy: 0.9370\n","Epoch 16/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0628 - accuracy: 0.9796 - val_loss: 0.1715 - val_accuracy: 0.9408\n","Epoch 17/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0503 - accuracy: 0.9828 - val_loss: 0.2004 - val_accuracy: 0.9408\n","Epoch 18/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.1921 - val_accuracy: 0.9351\n","Epoch 19/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9828 - val_loss: 0.1725 - val_accuracy: 0.9408\n","Epoch 20/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.1660 - val_accuracy: 0.9370\n","Epoch 21/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0384 - accuracy: 0.9886 - val_loss: 0.1612 - val_accuracy: 0.9427\n","Epoch 22/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.1750 - val_accuracy: 0.9485\n","Epoch 23/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9841 - val_loss: 0.1530 - val_accuracy: 0.9504\n","Epoch 24/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 0.1756 - val_accuracy: 0.9447\n","Epoch 25/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9879 - val_loss: 0.1643 - val_accuracy: 0.9485\n","Epoch 26/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0439 - accuracy: 0.9895 - val_loss: 0.1523 - val_accuracy: 0.9466\n","Epoch 27/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.1504 - val_accuracy: 0.9447\n","Epoch 28/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.1535 - val_accuracy: 0.9523\n","Epoch 29/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9901 - val_loss: 0.1982 - val_accuracy: 0.9351\n","Epoch 30/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9861 - val_loss: 0.1679 - val_accuracy: 0.9542\n","Epoch 31/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.1638 - val_accuracy: 0.9427\n","Epoch 32/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.1525 - val_accuracy: 0.9523\n","Epoch 33/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.1612 - val_accuracy: 0.9561\n","Epoch 34/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.1613 - val_accuracy: 0.9542\n","Epoch 35/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.1616 - val_accuracy: 0.9485\n","Epoch 36/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9910 - val_loss: 0.1546 - val_accuracy: 0.9466\n","Epoch 37/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.1723 - val_accuracy: 0.9485\n","Epoch 38/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0168 - accuracy: 0.9913 - val_loss: 0.1749 - val_accuracy: 0.9523\n","Epoch 39/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 0.1748 - val_accuracy: 0.9504\n","Epoch 40/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 0.1841 - val_accuracy: 0.9542\n","Epoch 41/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.1610 - val_accuracy: 0.9504\n","Epoch 42/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.1950 - val_accuracy: 0.9504\n","Epoch 43/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.1631 - val_accuracy: 0.9542\n","Epoch 44/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.1659 - val_accuracy: 0.9504\n","Epoch 45/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.1576 - val_accuracy: 0.9561\n","Epoch 46/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.1941 - val_accuracy: 0.9466\n","Epoch 47/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.1627 - val_accuracy: 0.9580\n","Epoch 48/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1621 - val_accuracy: 0.9485\n","Epoch 49/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.1630 - val_accuracy: 0.9523\n","Epoch 50/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.1735 - val_accuracy: 0.9523\n","Epoch 51/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.1756 - val_accuracy: 0.9542\n","Epoch 52/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.1894 - val_accuracy: 0.9466\n","Epoch 53/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1745 - val_accuracy: 0.9542\n","Epoch 54/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.2302 - val_accuracy: 0.9447\n","Epoch 55/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.2094 - val_accuracy: 0.9485\n","Epoch 56/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9950 - val_loss: 0.2072 - val_accuracy: 0.9523\n","Epoch 57/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.1872 - val_accuracy: 0.9485\n","Epoch 58/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9943 - val_loss: 0.2336 - val_accuracy: 0.9408\n","Epoch 59/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.1793 - val_accuracy: 0.9504\n","Epoch 60/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1764 - val_accuracy: 0.9485\n","Epoch 61/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.1788 - val_accuracy: 0.9542\n","Epoch 62/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9955 - val_loss: 0.1982 - val_accuracy: 0.9523\n","Epoch 63/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.2109 - val_accuracy: 0.9561\n","Epoch 64/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.2053 - val_accuracy: 0.9542\n","Epoch 65/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9961 - val_loss: 0.2093 - val_accuracy: 0.9504\n","Epoch 66/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.1968 - val_accuracy: 0.9504\n","Epoch 67/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.2070 - val_accuracy: 0.9466\n","Epoch 68/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.1602 - val_accuracy: 0.9599\n","Epoch 69/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.1831 - val_accuracy: 0.9542\n","Epoch 70/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9976 - val_loss: 0.2177 - val_accuracy: 0.9580\n","Epoch 71/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2264 - val_accuracy: 0.9561\n","Epoch 72/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.2149 - val_accuracy: 0.9542\n","Epoch 73/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9965 - val_loss: 0.2192 - val_accuracy: 0.9523\n","Epoch 74/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.2090 - val_accuracy: 0.9542\n","Epoch 75/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.1996 - val_accuracy: 0.9523\n","Epoch 76/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.1997 - val_accuracy: 0.9542\n","Epoch 77/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.1941 - val_accuracy: 0.9561\n","Epoch 78/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9656\n","Epoch 79/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9504\n","Epoch 80/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.2107 - val_accuracy: 0.9504\n","Epoch 81/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.2597 - val_accuracy: 0.9447\n","Epoch 82/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9599\n","Epoch 83/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1841 - val_accuracy: 0.9618\n","Epoch 84/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.1952 - val_accuracy: 0.9561\n","Epoch 85/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9504\n","Epoch 86/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.1909 - val_accuracy: 0.9695\n","Epoch 87/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1956 - val_accuracy: 0.9599\n","Epoch 88/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.8982e-04 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9580\n","Epoch 89/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.2064 - val_accuracy: 0.9542\n","Epoch 90/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.2128 - val_accuracy: 0.9656\n","Epoch 91/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1935 - val_accuracy: 0.9599\n","Epoch 92/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9599\n","Epoch 93/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.1651e-04 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9618\n","Epoch 94/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9466\n","Epoch 95/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.0550e-04 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9599\n","Epoch 96/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 9.3675e-04 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9523\n","Epoch 97/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9561\n","Epoch 98/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9599\n","Epoch 99/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9561\n","Epoch 100/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 0.2508 - val_accuracy: 0.9466\n","Epoch 101/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9523\n","Epoch 102/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.2077 - val_accuracy: 0.9618\n","Epoch 103/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.2043 - val_accuracy: 0.9561\n","Epoch 104/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.2077 - val_accuracy: 0.9656\n","Epoch 105/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9978 - val_loss: 0.2095 - val_accuracy: 0.9599\n","Epoch 106/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9656\n","Epoch 107/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 0.1903 - val_accuracy: 0.9618\n","Epoch 108/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.2746 - val_accuracy: 0.9561\n","Epoch 109/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.2683 - val_accuracy: 0.9466\n","Epoch 110/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.2598e-04 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9561\n","Epoch 111/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9561\n","Epoch 112/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.2560 - val_accuracy: 0.9504\n","Epoch 113/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.2277 - val_accuracy: 0.9561\n","Epoch 114/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9973 - val_loss: 0.2242 - val_accuracy: 0.9523\n","Epoch 115/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.2478 - val_accuracy: 0.9561\n","Epoch 116/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.9404e-04 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9599\n","Epoch 117/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.2734 - val_accuracy: 0.9523\n","Epoch 118/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.2533 - val_accuracy: 0.9561\n","Epoch 119/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.2511 - val_accuracy: 0.9580\n","Epoch 120/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 9.0719e-04 - accuracy: 0.9999 - val_loss: 0.2415 - val_accuracy: 0.9561\n","Epoch 121/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.2940 - val_accuracy: 0.9504\n","Epoch 122/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.2301 - val_accuracy: 0.9580\n","Epoch 123/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.4499e-04 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9618\n","Epoch 124/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 0.3004 - val_accuracy: 0.9504\n","Epoch 125/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.2700 - val_accuracy: 0.9523\n","Epoch 126/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9985 - val_loss: 0.2476 - val_accuracy: 0.9618\n","Epoch 127/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9656\n","Epoch 128/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.3259 - val_accuracy: 0.9447\n","Epoch 129/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 8.8416e-04 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9599\n","Epoch 130/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.2618 - val_accuracy: 0.9504\n","Epoch 131/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.2311 - val_accuracy: 0.9599\n","Epoch 132/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9580\n","Epoch 133/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.6578e-04 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9485\n","Epoch 134/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2489 - val_accuracy: 0.9676\n","Epoch 135/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9983 - val_loss: 0.2570 - val_accuracy: 0.9561\n","Epoch 136/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.1472e-04 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9523\n","Epoch 137/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.8910e-04 - accuracy: 0.9998 - val_loss: 0.2404 - val_accuracy: 0.9599\n","Epoch 138/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.2234 - val_accuracy: 0.9637\n","Epoch 139/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.0722e-04 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9580\n","Epoch 140/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.4019e-04 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9676\n","Epoch 141/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.2648 - val_accuracy: 0.9561\n","Epoch 142/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.3105e-04 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9676\n","Epoch 143/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.0542e-04 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9599\n","Epoch 144/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.4285e-04 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9618\n","Epoch 145/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.3241e-04 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9580\n","Epoch 146/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.9432e-05 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9580\n","Epoch 147/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.3326e-04 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9561\n","Epoch 148/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.0360e-04 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9656\n","Epoch 149/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.9253e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9504\n","Epoch 150/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 8.0084e-04 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9523\n","Epoch 151/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.4494e-04 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9637\n","Epoch 152/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.3667 - val_accuracy: 0.9427\n","Epoch 153/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9580\n","Epoch 154/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.5017e-04 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9599\n","Epoch 155/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9981 - val_loss: 0.2817 - val_accuracy: 0.9561\n","Epoch 156/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9976 - val_loss: 0.2835 - val_accuracy: 0.9504\n","Epoch 157/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3465 - val_accuracy: 0.9408\n","Epoch 158/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9466\n","Epoch 159/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.2500 - val_accuracy: 0.9542\n","Epoch 160/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.4141e-04 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9580\n","Epoch 161/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 8.4792e-05 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9542\n","Epoch 162/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.3427e-04 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9561\n","Epoch 163/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.2278 - val_accuracy: 0.9618\n","Epoch 164/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 9.7477e-04 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9561\n","Epoch 165/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9983 - val_loss: 0.2772 - val_accuracy: 0.9542\n","Epoch 166/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 0.2973 - val_accuracy: 0.9542\n","Epoch 167/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.6150e-04 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9542\n","Epoch 168/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 9.3555e-04 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9542\n","Epoch 169/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2838 - val_accuracy: 0.9542\n","Epoch 170/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8976e-04 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9580\n","Epoch 171/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.6722e-05 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9523\n","Epoch 172/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.7785e-05 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9561\n","Epoch 173/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.2675e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9542\n","Epoch 174/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 6.3363e-05 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9580\n","Epoch 175/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.3287e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9580\n","Epoch 176/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 0.2430 - val_accuracy: 0.9523\n","Epoch 177/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.4397e-04 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9447\n","Epoch 178/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2832 - val_accuracy: 0.9504\n","Epoch 179/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.2649 - val_accuracy: 0.9599\n","Epoch 180/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.2745e-04 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9523\n","Epoch 181/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 6.0075e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9580\n","Epoch 182/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.0548e-04 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9561\n","Epoch 183/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 0.2354 - val_accuracy: 0.9637\n","Epoch 184/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.8019e-04 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9561\n","Epoch 185/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.8790e-04 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9618\n","Epoch 186/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.2787 - val_accuracy: 0.9599\n","Epoch 187/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.0196e-04 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9637\n","Epoch 188/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.0153e-04 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9504\n","Epoch 189/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9958 - val_loss: 0.3019 - val_accuracy: 0.9618\n","Epoch 190/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.7221e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9656\n","Epoch 191/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9949 - val_loss: 0.2510 - val_accuracy: 0.9580\n","Epoch 192/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.0464e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9485\n","Epoch 193/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.7067e-04 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9580\n","Epoch 194/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.7642e-04 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9580\n","Epoch 195/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.0097e-04 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9580\n","Epoch 196/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.2594e-04 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9637\n","Epoch 197/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.4234e-04 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9637\n","Epoch 198/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.4614e-04 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9618\n","Epoch 199/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.6883e-05 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9637\n","Epoch 200/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.4083e-05 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9637\n","Epoch 201/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.1788e-05 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9580\n","Epoch 202/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.6177e-05 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9618\n","Epoch 203/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.3303e-05 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9637\n","Epoch 204/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.2455e-05 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9676\n","Epoch 205/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.9215e-04 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9695\n","Epoch 206/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.0863e-04 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.9637\n","Epoch 207/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.3630 - val_accuracy: 0.9485\n","Epoch 208/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.3130 - val_accuracy: 0.9618\n","Epoch 209/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9986 - val_loss: 0.3179 - val_accuracy: 0.9504\n","Epoch 210/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.2958 - val_accuracy: 0.9676\n","Epoch 211/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9983 - val_loss: 0.2885 - val_accuracy: 0.9656\n","Epoch 212/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.0930e-04 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9618\n","Epoch 213/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.0291e-05 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9618\n","Epoch 214/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.2362e-04 - accuracy: 1.0000 - val_loss: 0.3185 - val_accuracy: 0.9580\n","Epoch 215/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.5571e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9599\n","Epoch 216/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 8.0375e-05 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.9599\n","Epoch 217/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 6.2021e-05 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9580\n","Epoch 218/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.2412e-05 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9580\n","Epoch 219/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.5473e-05 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9599\n","Epoch 220/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 8.6238e-05 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9637\n","Epoch 221/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.0904e-04 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9599\n","Epoch 222/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 6.4295e-04 - accuracy: 0.9995 - val_loss: 0.3537 - val_accuracy: 0.9637\n","Epoch 223/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.3613 - val_accuracy: 0.9580\n","Epoch 224/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.3430 - val_accuracy: 0.9504\n","Epoch 225/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.5458e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9542\n","Epoch 226/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 8.8028e-05 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9542\n","Epoch 227/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.0113e-04 - accuracy: 0.9999 - val_loss: 0.3580 - val_accuracy: 0.9618\n","Epoch 228/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.5830e-04 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9542\n","Epoch 229/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.5126e-04 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9523\n","Epoch 230/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7180e-04 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9542\n","Epoch 231/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.9888e-05 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9561\n","Epoch 232/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.4742e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9561\n","Epoch 233/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3912e-04 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9618\n","Epoch 234/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.1610e-05 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9637\n","Epoch 235/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3142e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9676\n","Epoch 236/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.2059e-04 - accuracy: 0.9999 - val_loss: 0.3800 - val_accuracy: 0.9580\n","Epoch 237/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.2683 - val_accuracy: 0.9618\n","Epoch 238/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9618\n","Epoch 239/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6937e-04 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9599\n","Epoch 240/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0846e-04 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9637\n","Epoch 241/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.2815 - val_accuracy: 0.9599\n","Epoch 242/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 6.7647e-04 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9618\n","Epoch 243/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.2180e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9656\n","Epoch 244/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.5380e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9637\n","Epoch 245/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.4834e-04 - accuracy: 0.9999 - val_loss: 0.4110 - val_accuracy: 0.9389\n","Epoch 246/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.3637e-04 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9637\n","Epoch 247/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 8.0721e-05 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9599\n","Epoch 248/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.0585e-04 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9618\n","Epoch 249/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.3027e-04 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9561\n","Epoch 250/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.3098e-05 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9561\n","Epoch 251/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 6.2515e-05 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9656\n","Epoch 252/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.8316e-05 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9637\n","Epoch 253/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.5632e-05 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9618\n","Epoch 254/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 0.2691 - val_accuracy: 0.9656\n","Epoch 255/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.7847e-04 - accuracy: 0.9997 - val_loss: 0.2767 - val_accuracy: 0.9561\n","Epoch 256/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.1280e-04 - accuracy: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.9561\n","Epoch 257/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.3241e-04 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9580\n","Epoch 258/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9155e-04 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.9676\n","Epoch 259/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.9609e-04 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9580\n","Epoch 260/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.7401e-04 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9637\n","Epoch 261/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.8882e-05 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9618\n","Epoch 262/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.6806e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9599\n","Epoch 263/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.6876e-04 - accuracy: 0.9998 - val_loss: 0.3300 - val_accuracy: 0.9637\n","Epoch 264/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9599\n","Epoch 265/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9984 - val_loss: 0.3168 - val_accuracy: 0.9561\n","Epoch 266/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.6683e-05 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9580\n","Epoch 267/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.7640e-04 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9485\n","Epoch 268/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.3246 - val_accuracy: 0.9618\n","Epoch 269/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.4628 - val_accuracy: 0.9294\n","Epoch 270/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9970 - val_loss: 0.3425 - val_accuracy: 0.9466\n","Epoch 271/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.7152e-04 - accuracy: 0.9994 - val_loss: 0.3281 - val_accuracy: 0.9618\n","Epoch 272/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.9240e-04 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9599\n","Epoch 273/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.3429e-05 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9580\n","Epoch 274/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.0685e-04 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.9599\n","Epoch 275/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.3832e-04 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9561\n","Epoch 276/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.1709e-05 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9580\n","Epoch 277/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.0123e-05 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9580\n","Epoch 278/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8728e-05 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9580\n","Epoch 279/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.6352e-05 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9637\n","Epoch 280/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0968e-05 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9618\n","Epoch 281/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.0737e-05 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9580\n","Epoch 282/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.5300e-05 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.9523\n","Epoch 283/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.4279e-05 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9656\n","Epoch 284/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.5143e-04 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.9599\n","Epoch 285/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0386e-05 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9618\n","Epoch 286/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.3189 - val_accuracy: 0.9618\n","Epoch 287/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9523\n","Epoch 288/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.2917 - val_accuracy: 0.9561\n","Epoch 289/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.3572 - val_accuracy: 0.9447\n","Epoch 290/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3722e-04 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9599\n","Epoch 291/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.0864e-05 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9580\n","Epoch 292/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0213e-05 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9580\n","Epoch 293/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.5697e-05 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9599\n","Epoch 294/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.3800e-05 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9561\n","Epoch 295/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.0503e-04 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9656\n","Epoch 296/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.4465e-05 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9656\n","Epoch 297/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.5151e-05 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9580\n","Epoch 298/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.8197e-05 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9618\n","Epoch 299/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1359e-05 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9676\n","Epoch 300/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.0198e-04 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9656\n","Epoch 301/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.9764e-05 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9656\n","Epoch 302/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9185e-05 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9676\n","Epoch 303/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.8936e-06 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9656\n","Epoch 304/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.9614e-06 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.9656\n","Epoch 305/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2206e-05 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9618\n","Epoch 306/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2201e-05 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9542\n","Epoch 307/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.5257e-05 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9637\n","Epoch 308/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.3771e-04 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9561\n","Epoch 309/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4179 - val_accuracy: 0.9637\n","Epoch 310/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.3493 - val_accuracy: 0.9580\n","Epoch 311/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.3028e-04 - accuracy: 0.9997 - val_loss: 0.3149 - val_accuracy: 0.9618\n","Epoch 312/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 7.6947e-05 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9618\n","Epoch 313/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.4961e-05 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9618\n","Epoch 314/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.2529e-05 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9637\n","Epoch 315/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.6818e-05 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9637\n","Epoch 316/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.6100e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9618\n","Epoch 317/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9989 - val_loss: 0.2843 - val_accuracy: 0.9542\n","Epoch 318/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3273 - val_accuracy: 0.9599\n","Epoch 319/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.6945e-04 - accuracy: 0.9994 - val_loss: 0.3311 - val_accuracy: 0.9599\n","Epoch 320/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0304e-05 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9618\n","Epoch 321/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 5.7830e-05 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9485\n","Epoch 322/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.3055 - val_accuracy: 0.9637\n","Epoch 323/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1554e-04 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9637\n","Epoch 324/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.6282e-05 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9656\n","Epoch 325/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.1120e-05 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9599\n","Epoch 326/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.3619e-05 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9618\n","Epoch 327/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.7093e-05 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9599\n","Epoch 328/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2698e-05 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9599\n","Epoch 329/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6006e-05 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9618\n","Epoch 330/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.3343e-04 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9637\n","Epoch 331/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.2564 - val_accuracy: 0.9618\n","Epoch 332/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.2013e-04 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9580\n","Epoch 333/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.4047e-04 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9637\n","Epoch 334/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.4883e-04 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9676\n","Epoch 335/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.0915e-05 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9676\n","Epoch 336/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.9621e-04 - accuracy: 0.9998 - val_loss: 0.3740 - val_accuracy: 0.9523\n","Epoch 337/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.2648 - val_accuracy: 0.9599\n","Epoch 338/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2661e-04 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9637\n","Epoch 339/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6724e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9637\n","Epoch 340/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9595e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9580\n","Epoch 341/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1951e-04 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9599\n","Epoch 342/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9230e-05 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9580\n","Epoch 343/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.1609e-05 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9599\n","Epoch 344/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.1969e-05 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9580\n","Epoch 345/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.0335e-05 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.9561\n","Epoch 346/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.4145e-05 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9618\n","Epoch 347/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.1967e-05 - accuracy: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.9561\n","Epoch 348/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1646e-04 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9580\n","Epoch 349/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.7692e-04 - accuracy: 0.9995 - val_loss: 0.3580 - val_accuracy: 0.9542\n","Epoch 350/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.9066e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9561\n","Epoch 351/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.8331e-05 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9561\n","Epoch 352/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.2194e-05 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9561\n","Epoch 353/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8210e-05 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9561\n","Epoch 354/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.7020e-05 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9542\n","Epoch 355/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6167e-04 - accuracy: 0.9999 - val_loss: 0.3052 - val_accuracy: 0.9695\n","Epoch 356/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3862e-04 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9561\n","Epoch 357/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.7322e-05 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9561\n","Epoch 358/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.7202e-05 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9580\n","Epoch 359/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.0194e-06 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9599\n","Epoch 360/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.2352e-05 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9695\n","Epoch 361/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1064e-05 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9676\n","Epoch 362/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.5481e-05 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9695\n","Epoch 363/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.2463e-04 - accuracy: 0.9998 - val_loss: 0.3229 - val_accuracy: 0.9676\n","Epoch 364/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0129 - accuracy: 0.9981 - val_loss: 0.3455 - val_accuracy: 0.9676\n","Epoch 365/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.3321e-05 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9656\n","Epoch 366/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7236e-04 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9580\n","Epoch 367/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.7763e-04 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9656\n","Epoch 368/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0320e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9637\n","Epoch 369/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.2827e-05 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.9676\n","Epoch 370/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8610e-05 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9656\n","Epoch 371/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.6915e-05 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.9656\n","Epoch 372/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.6112e-05 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9714\n","Epoch 373/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.4051 - val_accuracy: 0.9580\n","Epoch 374/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9580\n","Epoch 375/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0433e-04 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9599\n","Epoch 376/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 6.0739e-05 - accuracy: 1.0000 - val_loss: 0.3261 - val_accuracy: 0.9618\n","Epoch 377/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.8500e-05 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9599\n","Epoch 378/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.5100e-05 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 0.9637\n","Epoch 379/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.7836e-04 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.9656\n","Epoch 380/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.2473e-05 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.9618\n","Epoch 381/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3472e-05 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9656\n","Epoch 382/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.3175e-05 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9599\n","Epoch 383/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5638e-05 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.9618\n","Epoch 384/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0673e-04 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.9695\n","Epoch 385/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.1641e-04 - accuracy: 0.9997 - val_loss: 0.3084 - val_accuracy: 0.9580\n","Epoch 386/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.2677 - val_accuracy: 0.9637\n","Epoch 387/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3666e-04 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9599\n","Epoch 388/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.8513e-05 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9561\n","Epoch 389/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.3720e-05 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9618\n","Epoch 390/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.3034 - val_accuracy: 0.9656\n","Epoch 391/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 6.2623e-05 - accuracy: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9637\n","Epoch 392/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 8.0585e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9637\n","Epoch 393/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6567e-04 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.9618\n","Epoch 394/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.6846e-05 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9637\n","Epoch 395/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 5.5745e-05 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9618\n","Epoch 396/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9405e-05 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9599\n","Epoch 397/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1720e-05 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9599\n","Epoch 398/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.3695 - val_accuracy: 0.9447\n","Epoch 399/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.1556e-04 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9561\n","Epoch 400/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9983 - val_loss: 0.3348 - val_accuracy: 0.9637\n","Epoch 401/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3694e-05 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9676\n","Epoch 402/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.7407e-05 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9676\n","Epoch 403/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.0062e-05 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9599\n","Epoch 404/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.3746e-04 - accuracy: 0.9998 - val_loss: 0.2834 - val_accuracy: 0.9618\n","Epoch 405/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.0302e-05 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9656\n","Epoch 406/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.0413e-04 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9656\n","Epoch 407/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8935e-05 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9637\n","Epoch 408/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.5617e-05 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9676\n","Epoch 409/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.8336e-04 - accuracy: 0.9999 - val_loss: 0.3676 - val_accuracy: 0.9580\n","Epoch 410/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 0.3703 - val_accuracy: 0.9656\n","Epoch 411/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.3204 - val_accuracy: 0.9637\n","Epoch 412/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0380e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9676\n","Epoch 413/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8839e-04 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9656\n","Epoch 414/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.9292e-05 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9695\n","Epoch 415/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6236e-05 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9676\n","Epoch 416/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9438e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9714\n","Epoch 417/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.8794e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9599\n","Epoch 418/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.3576 - val_accuracy: 0.9504\n","Epoch 419/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8586e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9523\n","Epoch 420/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.5690e-05 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9561\n","Epoch 421/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0881e-04 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9561\n","Epoch 422/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2226e-05 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9561\n","Epoch 423/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1086e-05 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9561\n","Epoch 424/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8773e-04 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9561\n","Epoch 425/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0406e-04 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9580\n","Epoch 426/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.5175e-05 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9580\n","Epoch 427/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.6026e-05 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9618\n","Epoch 428/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.8242e-05 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9676\n","Epoch 429/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.5190 - val_accuracy: 0.9466\n","Epoch 430/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.6182e-04 - accuracy: 0.9997 - val_loss: 0.3612 - val_accuracy: 0.9656\n","Epoch 431/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2979e-05 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9656\n","Epoch 432/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3608e-04 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9656\n","Epoch 433/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.3447 - val_accuracy: 0.9580\n","Epoch 434/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0241e-04 - accuracy: 0.9998 - val_loss: 0.3762 - val_accuracy: 0.9599\n","Epoch 435/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.3214e-05 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9618\n","Epoch 436/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.9865e-05 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9599\n","Epoch 437/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4374e-04 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9599\n","Epoch 438/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1999e-05 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9599\n","Epoch 439/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.7648e-06 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9599\n","Epoch 440/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.8913e-06 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9618\n","Epoch 441/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.8648e-05 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9656\n","Epoch 442/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.1744e-05 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9676\n","Epoch 443/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.8784e-05 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9656\n","Epoch 444/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.7312e-05 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9656\n","Epoch 445/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3426e-05 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9637\n","Epoch 446/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9488e-06 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9637\n","Epoch 447/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.5886e-05 - accuracy: 1.0000 - val_loss: 0.5601 - val_accuracy: 0.9427\n","Epoch 448/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.3734 - val_accuracy: 0.9656\n","Epoch 449/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7577e-05 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9656\n","Epoch 450/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1043e-04 - accuracy: 0.9998 - val_loss: 0.3401 - val_accuracy: 0.9695\n","Epoch 451/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3604e-04 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9676\n","Epoch 452/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 0.2751 - val_accuracy: 0.9695\n","Epoch 453/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.5880e-04 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9676\n","Epoch 454/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4618e-04 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9676\n","Epoch 455/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.1775e-04 - accuracy: 0.9999 - val_loss: 0.3521 - val_accuracy: 0.9599\n","Epoch 456/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6164e-04 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.9656\n","Epoch 457/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.7354e-05 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9637\n","Epoch 458/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6792e-05 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.9656\n","Epoch 459/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.1938e-05 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9656\n","Epoch 460/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2261e-04 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.9618\n","Epoch 461/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.7179e-05 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9637\n","Epoch 462/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.5918e-05 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.9656\n","Epoch 463/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.7931e-05 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9618\n","Epoch 464/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.7802e-05 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9695\n","Epoch 465/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.6853e-05 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9695\n","Epoch 466/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.0327e-05 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9695\n","Epoch 467/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.1654e-06 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9695\n","Epoch 468/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.2849e-06 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9695\n","Epoch 469/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.0319e-06 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9695\n","Epoch 470/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.0038e-06 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9695\n","Epoch 471/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.5859e-05 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9695\n","Epoch 472/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1207e-05 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9676\n","Epoch 473/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3104e-05 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9676\n","Epoch 474/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.3240e-05 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9676\n","Epoch 475/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.5680e-05 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9714\n","Epoch 476/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0080e-05 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.9714\n","Epoch 477/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1689e-04 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9542\n","Epoch 478/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.7801e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9580\n","Epoch 479/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.6337e-06 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9599\n","Epoch 480/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.3029e-04 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.9637\n","Epoch 481/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 4.3223e-05 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.9637\n","Epoch 482/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.1902e-05 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9580\n","Epoch 483/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.5656e-04 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9523\n","Epoch 484/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3474e-05 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9618\n","Epoch 485/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5822e-04 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9676\n","Epoch 486/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2901 - val_accuracy: 0.9656\n","Epoch 487/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.3464e-04 - accuracy: 1.0000 - val_loss: 0.3164 - val_accuracy: 0.9676\n","Epoch 488/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.0897e-05 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9637\n","Epoch 489/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1539e-05 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9637\n","Epoch 490/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.3531e-05 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9637\n","Epoch 491/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6668e-05 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9656\n","Epoch 492/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1277e-05 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9676\n","Epoch 493/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2872e-05 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9714\n","Epoch 494/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.3170e-05 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9714\n","Epoch 495/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.3827e-06 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9714\n","Epoch 496/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.2464e-05 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9637\n","Epoch 497/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 6.1294e-05 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9580\n","Epoch 498/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.8775e-06 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9656\n","Epoch 499/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0013e-05 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9676\n","Epoch 500/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.5007e-04 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9542\n","Epoch 501/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.5685e-04 - accuracy: 0.9997 - val_loss: 0.3936 - val_accuracy: 0.9618\n","Epoch 502/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0343e-04 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9695\n","Epoch 503/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9978 - val_loss: 0.3194 - val_accuracy: 0.9637\n","Epoch 504/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.8149e-05 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9542\n","Epoch 505/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3235 - val_accuracy: 0.9676\n","Epoch 506/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5951e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9561\n","Epoch 507/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2053e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9599\n","Epoch 508/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.7006e-05 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9676\n","Epoch 509/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9129e-06 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9676\n","Epoch 510/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0873e-06 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9676\n","Epoch 511/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4824e-04 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9714\n","Epoch 512/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1077e-04 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9695\n","Epoch 513/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.2938e-06 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9695\n","Epoch 514/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.7605e-06 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9676\n","Epoch 515/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0737e-05 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9637\n","Epoch 516/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.2597e-06 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9637\n","Epoch 517/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0367e-06 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9656\n","Epoch 518/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.2844e-06 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9656\n","Epoch 519/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5104e-05 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9676\n","Epoch 520/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2382e-05 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9676\n","Epoch 521/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0418e-05 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9618\n","Epoch 522/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.4844e-06 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9599\n","Epoch 523/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.0079e-06 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.9714\n","Epoch 524/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0168e-04 - accuracy: 1.0000 - val_loss: 0.6032 - val_accuracy: 0.9466\n","Epoch 525/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3169e-05 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9580\n","Epoch 526/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.0818e-05 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9618\n","Epoch 527/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.7956e-06 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9618\n","Epoch 528/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.7996e-06 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9656\n","Epoch 529/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.4318 - val_accuracy: 0.9542\n","Epoch 530/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.9614e-05 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.9542\n","Epoch 531/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0286e-04 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9523\n","Epoch 532/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9656\n","Epoch 533/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.4832e-05 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9656\n","Epoch 534/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2167e-05 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9714\n","Epoch 535/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.3342e-05 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9676\n","Epoch 536/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.4035e-06 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9676\n","Epoch 537/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9451e-05 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9676\n","Epoch 538/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 2.0543e-05 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9656\n","Epoch 539/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.7608e-06 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9656\n","Epoch 540/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.4610e-06 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9618\n","Epoch 541/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4280e-04 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9485\n","Epoch 542/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.8446e-05 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9618\n","Epoch 543/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 1.5733e-05 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9676\n","Epoch 544/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.6941e-06 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9656\n","Epoch 545/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.8014e-06 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.9542\n","Epoch 546/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8912e-04 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.9523\n","Epoch 547/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.9738e-05 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9561\n","Epoch 548/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.2319e-06 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9599\n","Epoch 549/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8644e-05 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.9656\n","Epoch 550/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6361e-06 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9656\n","Epoch 551/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7298e-06 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.9656\n","Epoch 552/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2641e-06 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.9676\n","Epoch 553/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.9914e-07 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9676\n","Epoch 554/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5440e-06 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9676\n","Epoch 555/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8120e-05 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.9637\n","Epoch 556/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.8763e-07 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9618\n","Epoch 557/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.3805e-05 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9523\n","Epoch 558/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.8251e-04 - accuracy: 0.9996 - val_loss: 0.5438 - val_accuracy: 0.9637\n","Epoch 559/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6247e-05 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.9542\n","Epoch 560/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9986 - val_loss: 0.3701 - val_accuracy: 0.9656\n","Epoch 561/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.4876 - val_accuracy: 0.9580\n","Epoch 562/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.0311e-04 - accuracy: 0.9994 - val_loss: 0.3898 - val_accuracy: 0.9580\n","Epoch 563/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8039e-05 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.9580\n","Epoch 564/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.4259e-04 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9656\n","Epoch 565/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9293e-05 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9599\n","Epoch 566/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3842e-05 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9599\n","Epoch 567/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2147e-04 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9618\n","Epoch 568/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.2390e-06 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9618\n","Epoch 569/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.5051e-06 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9618\n","Epoch 570/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.5692e-05 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9561\n","Epoch 571/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.8433e-05 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9580\n","Epoch 572/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.6439e-06 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9561\n","Epoch 573/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2860e-05 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9561\n","Epoch 574/1000\n","244/244 [==============================] - 1s 4ms/step - loss: 3.2297e-06 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9561\n","Epoch 575/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.4663e-04 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9714\n","Epoch 576/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6452e-05 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9695\n","Epoch 577/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5799e-06 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9695\n","Epoch 578/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.9351e-05 - accuracy: 1.0000 - val_loss: 0.3771 - val_accuracy: 0.9733\n","Epoch 579/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8605e-05 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 0.9637\n","Epoch 580/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4829e-06 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9637\n","Epoch 581/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.7805e-06 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9637\n","Epoch 582/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4148e-06 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9656\n","Epoch 583/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4703e-06 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9637\n","Epoch 584/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3332e-07 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9637\n","Epoch 585/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.7523e-07 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9656\n","Epoch 586/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2568e-05 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9656\n","Epoch 587/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.3860 - val_accuracy: 0.9695\n","Epoch 588/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0784e-04 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9637\n","Epoch 589/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.6768e-06 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.9580\n","Epoch 590/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.3713e-05 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9656\n","Epoch 591/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1064e-05 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9676\n","Epoch 592/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2112e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9637\n","Epoch 593/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.7052e-05 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9618\n","Epoch 594/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7814e-05 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9599\n","Epoch 595/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.2917e-06 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9599\n","Epoch 596/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.5802e-05 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9580\n","Epoch 597/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.3288e-06 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.9580\n","Epoch 598/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1790e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9599\n","Epoch 599/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1573e-05 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.9523\n","Epoch 600/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.4743 - val_accuracy: 0.9676\n","Epoch 601/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5791e-05 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9676\n","Epoch 602/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.6944e-04 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9580\n","Epoch 603/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.4450e-04 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9599\n","Epoch 604/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9847e-04 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9656\n","Epoch 605/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3854e-05 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9656\n","Epoch 606/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2196e-05 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9676\n","Epoch 607/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.6918e-06 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9676\n","Epoch 608/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.0916e-06 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9676\n","Epoch 609/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3301e-05 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9637\n","Epoch 610/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.2878e-07 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.9637\n","Epoch 611/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2947e-05 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9676\n","Epoch 612/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6660e-05 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.9637\n","Epoch 613/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9509e-06 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9580\n","Epoch 614/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.4801e-06 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.9599\n","Epoch 615/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0017e-06 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9618\n","Epoch 616/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.5694e-06 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9695\n","Epoch 617/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.8049e-07 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9695\n","Epoch 618/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.3131e-06 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9695\n","Epoch 619/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.5381e-06 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9695\n","Epoch 620/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.6246e-05 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9695\n","Epoch 621/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.0292e-06 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9637\n","Epoch 622/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.6241e-07 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.9618\n","Epoch 623/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.9026e-06 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9599\n","Epoch 624/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.4073e-05 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9599\n","Epoch 625/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3609e-05 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9637\n","Epoch 626/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5124e-07 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.9599\n","Epoch 627/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0098e-06 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.9618\n","Epoch 628/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.9337e-06 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9637\n","Epoch 629/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.9732e-06 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9599\n","Epoch 630/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.0176e-07 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.9618\n","Epoch 631/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1022e-06 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.9599\n","Epoch 632/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.8571e-07 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9618\n","Epoch 633/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9257e-07 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9599\n","Epoch 634/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.8400e-07 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9618\n","Epoch 635/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.1166e-07 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9618\n","Epoch 636/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2858e-06 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9637\n","Epoch 637/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.2858e-07 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.9637\n","Epoch 638/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.1458e-07 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9580\n","Epoch 639/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.4009e-06 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.9523\n","Epoch 640/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.9949 - val_loss: 0.5962 - val_accuracy: 0.9523\n","Epoch 641/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.5799e-05 - accuracy: 1.0000 - val_loss: 0.5601 - val_accuracy: 0.9523\n","Epoch 642/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1144e-05 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.9523\n","Epoch 643/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4789e-04 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9580\n","Epoch 644/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2175e-05 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.9599\n","Epoch 645/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.9270e-04 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.9523\n","Epoch 646/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.4083 - val_accuracy: 0.9656\n","Epoch 647/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.1254e-06 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9656\n","Epoch 648/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5229e-05 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9656\n","Epoch 649/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1219e-05 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9637\n","Epoch 650/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.9392e-06 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9637\n","Epoch 651/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.8380e-05 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9599\n","Epoch 652/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.7709e-05 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9599\n","Epoch 653/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.2714e-06 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9599\n","Epoch 654/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1798e-06 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9618\n","Epoch 655/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9975 - val_loss: 0.4135 - val_accuracy: 0.9676\n","Epoch 656/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.0435e-06 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9676\n","Epoch 657/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.0218e-05 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9733\n","Epoch 658/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.5233e-06 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9733\n","Epoch 659/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8188e-05 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9733\n","Epoch 660/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.9139e-06 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9695\n","Epoch 661/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.2688e-05 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9676\n","Epoch 662/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.2769e-07 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9695\n","Epoch 663/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6271e-05 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9714\n","Epoch 664/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1126e-06 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9714\n","Epoch 665/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8478e-06 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.9714\n","Epoch 666/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9986 - val_loss: 0.4468 - val_accuracy: 0.9656\n","Epoch 667/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0881e-04 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9676\n","Epoch 668/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0728e-04 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9561\n","Epoch 669/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0206e-05 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9542\n","Epoch 670/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.5058e-07 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9542\n","Epoch 671/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2188e-06 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9542\n","Epoch 672/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4261 - val_accuracy: 0.9618\n","Epoch 673/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.2790e-05 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9618\n","Epoch 674/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1271e-04 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9656\n","Epoch 675/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6991e-04 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9676\n","Epoch 676/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8235e-05 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.9695\n","Epoch 677/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5435e-06 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9695\n","Epoch 678/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.9419e-05 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9637\n","Epoch 679/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.7603e-07 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9637\n","Epoch 680/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4767e-06 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9637\n","Epoch 681/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.9360e-07 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9637\n","Epoch 682/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3217e-07 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9637\n","Epoch 683/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6048e-06 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9637\n","Epoch 684/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0331e-06 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.9637\n","Epoch 685/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1990e-06 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.9637\n","Epoch 686/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0714e-06 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9637\n","Epoch 687/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6486e-07 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9637\n","Epoch 688/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4601e-07 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9637\n","Epoch 689/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.3880e-06 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9618\n","Epoch 690/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8389e-05 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9676\n","Epoch 691/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0745e-04 - accuracy: 0.9999 - val_loss: 0.4426 - val_accuracy: 0.9637\n","Epoch 692/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.5317 - val_accuracy: 0.9466\n","Epoch 693/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0299 - accuracy: 0.9985 - val_loss: 0.4825 - val_accuracy: 0.9599\n","Epoch 694/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.1714e-05 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9618\n","Epoch 695/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.2061e-05 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9637\n","Epoch 696/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.4013 - val_accuracy: 0.9580\n","Epoch 697/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4709e-04 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9618\n","Epoch 698/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1213e-04 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9676\n","Epoch 699/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.5989e-05 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9637\n","Epoch 700/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 0.3757 - val_accuracy: 0.9695\n","Epoch 701/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.4826e-05 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9695\n","Epoch 702/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7633e-05 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9695\n","Epoch 703/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0104e-04 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9637\n","Epoch 704/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.3065e-06 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.9656\n","Epoch 705/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7992e-05 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 0.9656\n","Epoch 706/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4096e-06 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9656\n","Epoch 707/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8618e-06 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 0.9656\n","Epoch 708/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9815e-05 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9656\n","Epoch 709/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1367e-06 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9656\n","Epoch 710/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0717e-06 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9676\n","Epoch 711/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9991 - val_loss: 0.3887 - val_accuracy: 0.9618\n","Epoch 712/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.1927e-05 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9676\n","Epoch 713/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9072e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9714\n","Epoch 714/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.2473e-06 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9714\n","Epoch 715/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.4131e-05 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9733\n","Epoch 716/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.1540e-06 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9733\n","Epoch 717/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1184e-06 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9733\n","Epoch 718/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.8229e-06 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9695\n","Epoch 719/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0998e-05 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9714\n","Epoch 720/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.7474e-06 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.9714\n","Epoch 721/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.1122e-05 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9618\n","Epoch 722/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.4457 - val_accuracy: 0.9618\n","Epoch 723/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1407e-04 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.9676\n","Epoch 724/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8113e-05 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9656\n","Epoch 725/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.4529 - val_accuracy: 0.9656\n","Epoch 726/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3924e-04 - accuracy: 0.9998 - val_loss: 0.4178 - val_accuracy: 0.9656\n","Epoch 727/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 3.6170e-06 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9676\n","Epoch 728/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.7448e-07 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9676\n","Epoch 729/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.2127e-05 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.9695\n","Epoch 730/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9492e-06 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9695\n","Epoch 731/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8902e-05 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9676\n","Epoch 732/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2909e-07 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9676\n","Epoch 733/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6220e-07 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9676\n","Epoch 734/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.9378e-05 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9695\n","Epoch 735/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8414e-06 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9695\n","Epoch 736/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.9259e-04 - accuracy: 0.9998 - val_loss: 0.5497 - val_accuracy: 0.9580\n","Epoch 737/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2552e-04 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.9599\n","Epoch 738/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1208e-04 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9637\n","Epoch 739/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.9423e-05 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9656\n","Epoch 740/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.4626 - val_accuracy: 0.9599\n","Epoch 741/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.2087e-06 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9599\n","Epoch 742/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.0472e-06 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9599\n","Epoch 743/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.8288e-06 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9637\n","Epoch 744/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4372e-06 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9637\n","Epoch 745/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.2974e-05 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.9542\n","Epoch 746/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.5484e-04 - accuracy: 0.9995 - val_loss: 0.4905 - val_accuracy: 0.9599\n","Epoch 747/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2091e-04 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9676\n","Epoch 748/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9111e-04 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9676\n","Epoch 749/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2138e-04 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9695\n","Epoch 750/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.7428e-05 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.9656\n","Epoch 751/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.9618\n","Epoch 752/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6737e-06 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9618\n","Epoch 753/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.1051e-07 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.9618\n","Epoch 754/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.5859e-05 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9618\n","Epoch 755/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0756e-06 - accuracy: 1.0000 - val_loss: 0.4781 - val_accuracy: 0.9618\n","Epoch 756/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1259e-04 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.9695\n","Epoch 757/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 4.9275e-06 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9695\n","Epoch 758/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0949e-06 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9695\n","Epoch 759/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.8087e-07 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9695\n","Epoch 760/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.6226e-06 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9695\n","Epoch 761/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.7844e-07 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9695\n","Epoch 762/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.8923e-07 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.9695\n","Epoch 763/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.0839e-06 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9637\n","Epoch 764/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.3784e-06 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9637\n","Epoch 765/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.4757e-07 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9618\n","Epoch 766/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1019e-06 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9599\n","Epoch 767/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2938e-06 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9618\n","Epoch 768/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.6223e-06 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9580\n","Epoch 769/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 9.5353e-06 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9618\n","Epoch 770/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.9225e-06 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 0.9523\n","Epoch 771/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9967 - val_loss: 0.5116 - val_accuracy: 0.9656\n","Epoch 772/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.4964e-04 - accuracy: 0.9999 - val_loss: 0.5268 - val_accuracy: 0.9542\n","Epoch 773/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.9341e-04 - accuracy: 0.9991 - val_loss: 0.4499 - val_accuracy: 0.9637\n","Epoch 774/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.6527e-06 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9637\n","Epoch 775/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.5458e-04 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9656\n","Epoch 776/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.5208e-06 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9637\n","Epoch 777/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9503e-05 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.9637\n","Epoch 778/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8191e-06 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.9656\n","Epoch 779/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2496e-06 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9656\n","Epoch 780/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.3554e-07 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.9656\n","Epoch 781/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3265e-06 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9656\n","Epoch 782/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9969e-04 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9637\n","Epoch 783/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.8783e-07 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.9637\n","Epoch 784/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.9475e-06 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9637\n","Epoch 785/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2921e-04 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9618\n","Epoch 786/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.4995e-04 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9618\n","Epoch 787/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6468e-04 - accuracy: 0.9999 - val_loss: 0.4717 - val_accuracy: 0.9580\n","Epoch 788/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0380e-04 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9618\n","Epoch 789/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.7249e-06 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9618\n","Epoch 790/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.1172e-06 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9637\n","Epoch 791/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3206e-05 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9637\n","Epoch 792/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.9688e-05 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9637\n","Epoch 793/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.7505e-07 - accuracy: 1.0000 - val_loss: 0.3976 - val_accuracy: 0.9618\n","Epoch 794/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.6373e-06 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9637\n","Epoch 795/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1623e-07 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9637\n","Epoch 796/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1787e-06 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9618\n","Epoch 797/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0193e-05 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.9637\n","Epoch 798/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 8.6511e-06 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9656\n","Epoch 799/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.7164e-06 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9561\n","Epoch 800/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.2840e-05 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9580\n","Epoch 801/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0264e-04 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9676\n","Epoch 802/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7857e-05 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.9676\n","Epoch 803/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6153e-04 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9676\n","Epoch 804/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.7058e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9656\n","Epoch 805/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.9585e-05 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9599\n","Epoch 806/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.7236e-05 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9618\n","Epoch 807/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.9525e-05 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9637\n","Epoch 808/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2535e-05 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9676\n","Epoch 809/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.4510 - val_accuracy: 0.9618\n","Epoch 810/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6846e-04 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.9561\n","Epoch 811/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.2512e-05 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9618\n","Epoch 812/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2894e-06 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9580\n","Epoch 813/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.3988e-04 - accuracy: 0.9999 - val_loss: 0.4311 - val_accuracy: 0.9637\n","Epoch 814/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.3675e-05 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.9714\n","Epoch 815/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8812e-04 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9676\n","Epoch 816/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.4143 - val_accuracy: 0.9618\n","Epoch 817/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.7987e-06 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9618\n","Epoch 818/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.2455e-06 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9695\n","Epoch 819/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.0433e-06 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9676\n","Epoch 820/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.2014e-04 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.9695\n","Epoch 821/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4532e-05 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9695\n","Epoch 822/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6370e-05 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.9695\n","Epoch 823/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.3930e-05 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9714\n","Epoch 824/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.7943e-05 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9580\n","Epoch 825/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.1336e-06 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9618\n","Epoch 826/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3889e-04 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9618\n","Epoch 827/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8983e-05 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.9695\n","Epoch 828/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1663e-05 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9676\n","Epoch 829/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.2582e-05 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.9656\n","Epoch 830/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.5830e-06 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.9676\n","Epoch 831/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.8396e-06 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9676\n","Epoch 832/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.8382e-04 - accuracy: 0.9998 - val_loss: 0.4716 - val_accuracy: 0.9561\n","Epoch 833/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 6.1672e-05 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9695\n","Epoch 834/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.2436e-05 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9676\n","Epoch 835/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.2997 - val_accuracy: 0.9618\n","Epoch 836/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0807e-04 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9656\n","Epoch 837/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.8510e-05 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9656\n","Epoch 838/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.8563e-04 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.9580\n","Epoch 839/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.2166e-04 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9752\n","Epoch 840/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4291e-05 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9714\n","Epoch 841/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1624e-04 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9676\n","Epoch 842/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.7265e-06 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9656\n","Epoch 843/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0404e-04 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9695\n","Epoch 844/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.3327e-06 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9676\n","Epoch 845/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0627e-05 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9676\n","Epoch 846/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1070e-05 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9695\n","Epoch 847/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0020e-05 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.9714\n","Epoch 848/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.7173e-06 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9714\n","Epoch 849/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9834e-06 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.9676\n","Epoch 850/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6384e-05 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9714\n","Epoch 851/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1101e-06 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9714\n","Epoch 852/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.9550e-06 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9714\n","Epoch 853/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.6005e-06 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9695\n","Epoch 854/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0850e-06 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9695\n","Epoch 855/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.0763e-06 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9714\n","Epoch 856/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.6742e-06 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9714\n","Epoch 857/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.1848e-06 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9580\n","Epoch 858/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7965e-06 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9580\n","Epoch 859/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.2651e-07 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9580\n","Epoch 860/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 9.6478e-07 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9580\n","Epoch 861/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2661e-07 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9580\n","Epoch 862/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6049e-06 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.9580\n","Epoch 863/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0162e-06 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.9580\n","Epoch 864/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.4501e-06 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9714\n","Epoch 865/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.3946e-07 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9714\n","Epoch 866/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7274e-07 - accuracy: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.9714\n","Epoch 867/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9816e-07 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9714\n","Epoch 868/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.0327e-06 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9656\n","Epoch 869/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.4980e-07 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9676\n","Epoch 870/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.7407e-07 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9580\n","Epoch 871/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2052e-06 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9580\n","Epoch 872/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.0693e-07 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9580\n","Epoch 873/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1089e-06 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9599\n","Epoch 874/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.8312e-07 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9599\n","Epoch 875/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8281e-05 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.9637\n","Epoch 876/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9985 - val_loss: 0.3295 - val_accuracy: 0.9695\n","Epoch 877/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.4881e-04 - accuracy: 0.9991 - val_loss: 0.4440 - val_accuracy: 0.9580\n","Epoch 878/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.0090e-07 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9580\n","Epoch 879/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.7192e-06 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9618\n","Epoch 880/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.1408e-06 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9618\n","Epoch 881/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.6639e-07 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.9637\n","Epoch 882/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.9099e-06 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.9656\n","Epoch 883/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.4740 - val_accuracy: 0.9656\n","Epoch 884/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.2245e-04 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.9637\n","Epoch 885/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.2249e-05 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9637\n","Epoch 886/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.2855e-06 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.9637\n","Epoch 887/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 8.0460e-06 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9656\n","Epoch 888/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 7.0300e-05 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9656\n","Epoch 889/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.8421e-06 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9656\n","Epoch 890/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.4733e-07 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 0.9656\n","Epoch 891/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4053e-06 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9656\n","Epoch 892/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.7802e-06 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.9637\n","Epoch 893/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 0.9993 - val_loss: 0.4536 - val_accuracy: 0.9637\n","Epoch 894/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0407e-05 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9676\n","Epoch 895/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.8098e-06 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9676\n","Epoch 896/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.4318e-05 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9656\n","Epoch 897/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.6723e-06 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9656\n","Epoch 898/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.2049e-06 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.9656\n","Epoch 899/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1453e-04 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9752\n","Epoch 900/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 9.0944e-06 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9752\n","Epoch 901/1000\n","244/244 [==============================] - 2s 6ms/step - loss: 2.2379e-05 - accuracy: 1.0000 - val_loss: 0.8089 - val_accuracy: 0.9466\n","Epoch 902/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.4582 - val_accuracy: 0.9599\n","Epoch 903/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0164e-06 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9618\n","Epoch 904/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.9370e-06 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9676\n","Epoch 905/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1957e-06 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9676\n","Epoch 906/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.7122e-07 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.9676\n","Epoch 907/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 6.4301e-07 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.9656\n","Epoch 908/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.0288e-06 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9695\n","Epoch 909/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.5399e-06 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9695\n","Epoch 910/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8605e-05 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9618\n","Epoch 911/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 4.2490e-07 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9618\n","Epoch 912/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.4733e-05 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9656\n","Epoch 913/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.4686e-05 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9561\n","Epoch 914/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 9.5767e-06 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9599\n","Epoch 915/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.4043e-06 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9599\n","Epoch 916/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.6289e-06 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.9561\n","Epoch 917/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.4139e-06 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9561\n","Epoch 918/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 8.3495e-05 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9656\n","Epoch 919/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 0.4335 - val_accuracy: 0.9618\n","Epoch 920/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.8010e-05 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9599\n","Epoch 921/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.2147e-07 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9599\n","Epoch 922/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.5812e-05 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.9599\n","Epoch 923/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.5226e-07 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9599\n","Epoch 924/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.2203e-07 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9599\n","Epoch 925/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 9.9411e-04 - accuracy: 0.9993 - val_loss: 0.5083 - val_accuracy: 0.9637\n","Epoch 926/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3614e-05 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.9637\n","Epoch 927/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.7631e-04 - accuracy: 0.9996 - val_loss: 0.4543 - val_accuracy: 0.9714\n","Epoch 928/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.2185e-05 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.9714\n","Epoch 929/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.1035e-06 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9714\n","Epoch 930/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.7813e-06 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9733\n","Epoch 931/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.7490e-05 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9676\n","Epoch 932/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 3.4655e-06 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9695\n","Epoch 933/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.5710e-07 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9695\n","Epoch 934/1000\n","244/244 [==============================] - 2s 6ms/step - loss: 6.6457e-06 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9695\n","Epoch 935/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.5143e-07 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9695\n","Epoch 936/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 2.5366e-05 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 0.9561\n","Epoch 937/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.1986e-04 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.9580\n","Epoch 938/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.9733\n","Epoch 939/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 5.6786e-05 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9656\n","Epoch 940/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0933e-06 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.9656\n","Epoch 941/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.4634e-06 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.9656\n","Epoch 942/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 3.4519e-05 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9656\n","Epoch 943/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0009e-07 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9656\n","Epoch 944/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 6.1373e-06 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9676\n","Epoch 945/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.4672e-06 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9676\n","Epoch 946/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3197e-06 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9656\n","Epoch 947/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.6669e-07 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.9656\n","Epoch 948/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1284e-06 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.9676\n","Epoch 949/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.6442e-06 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9676\n","Epoch 950/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.9242e-07 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9676\n","Epoch 951/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.6000e-06 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9656\n","Epoch 952/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.5284e-06 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9637\n","Epoch 953/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.5721e-05 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.9676\n","Epoch 954/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.5201e-06 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9656\n","Epoch 955/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 4.7729e-07 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9656\n","Epoch 956/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.9549e-07 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9656\n","Epoch 957/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.8046e-07 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.9656\n","Epoch 958/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.2180e-07 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.9656\n","Epoch 959/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.0980e-07 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9676\n","Epoch 960/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.6421e-07 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9676\n","Epoch 961/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.2722e-06 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9676\n","Epoch 962/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.8898e-06 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.9695\n","Epoch 963/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.5044e-07 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9695\n","Epoch 964/1000\n","244/244 [==============================] - 1s 6ms/step - loss: 1.3276e-07 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9695\n","Epoch 965/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.0256e-06 - accuracy: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.9561\n","Epoch 966/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1554e-04 - accuracy: 1.0000 - val_loss: 0.5897 - val_accuracy: 0.9714\n","Epoch 967/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 0.5845 - val_accuracy: 0.9656\n","Epoch 968/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.5340 - val_accuracy: 0.9542\n","Epoch 969/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.1420e-06 - accuracy: 1.0000 - val_loss: 0.5297 - val_accuracy: 0.9542\n","Epoch 970/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.4283e-06 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.9561\n","Epoch 971/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.4806e-07 - accuracy: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.9561\n","Epoch 972/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9381e-04 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.9561\n","Epoch 973/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.4867e-06 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.9542\n","Epoch 974/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.3851e-06 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9561\n","Epoch 975/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.8609e-07 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.9561\n","Epoch 976/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.5974 - val_accuracy: 0.9580\n","Epoch 977/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 8.8108e-05 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9599\n","Epoch 978/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.4041 - val_accuracy: 0.9618\n","Epoch 979/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.1920e-04 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.9599\n","Epoch 980/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0116e-04 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9561\n","Epoch 981/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 9.0566e-07 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9542\n","Epoch 982/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.3416e-05 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9599\n","Epoch 983/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.0488e-05 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9580\n","Epoch 984/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7757e-06 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.9599\n","Epoch 985/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.2763e-05 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9637\n","Epoch 986/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0019e-05 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9637\n","Epoch 987/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9115e-05 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9618\n","Epoch 988/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.7391e-06 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9618\n","Epoch 989/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.4367e-06 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.9637\n","Epoch 990/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 6.1889e-07 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.9637\n","Epoch 991/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 7.8225e-06 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9637\n","Epoch 992/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.3986 - val_accuracy: 0.9676\n","Epoch 993/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 3.4404e-05 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9695\n","Epoch 994/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.9781e-05 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9676\n","Epoch 995/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.0246e-04 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9656\n","Epoch 996/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.2472e-05 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9676\n","Epoch 997/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 5.5920e-05 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9676\n","Epoch 998/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 2.1123e-05 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.9676\n","Epoch 999/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 1.9749e-06 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9676\n","Epoch 1000/1000\n","244/244 [==============================] - 1s 5ms/step - loss: 4.8502e-06 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9695\n","CNN Error: 3.05%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":805},"id":"Pm57jXEXVIuN","executionInfo":{"elapsed":829,"status":"ok","timestamp":1613376595882,"user":{"displayName":"Anna Mosenzon","photoUrl":"","userId":"16011365326734362597"},"user_tz":-120},"outputId":"66aadaf3-9549-4e49-ebdd-c0b7e3772c80"},"source":["y_test_predicted = NN.predict(X_test_nn)\r\n","y_train_predicted = NN.predict(X_train_nn)\r\n","y_test_classes_predicted = y_test_predicted.argmax(axis = -1)\r\n","y_train_classes_predicted = y_train_predicted.argmax(axis = -1)\r\n","y_train_classes = y_train_nn.argmax(axis = -1)\r\n","y_test_classes = y_test_nn.argmax(axis = -1)\r\n","\r\n","print(\"Test results:\")\r\n","print_results(y_test_classes, y_test_classes_predicted)\r\n","print(\"Train results:\")\r\n","print_results(y_train_classes, y_train_classes_predicted)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.9897</td>\n","      <td>0.9697</td>\n","      <td>0.9796</td>\n","      <td>198.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.9578</td>\n","      <td>0.9578</td>\n","      <td>0.9578</td>\n","      <td>166.0000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.9573</td>\n","      <td>0.9812</td>\n","      <td>0.9691</td>\n","      <td>160.0000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.9695</td>\n","      <td>0.9695</td>\n","      <td>0.9695</td>\n","      <td>0.9695</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.9683</td>\n","      <td>0.9696</td>\n","      <td>0.9689</td>\n","      <td>524.0000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.9697</td>\n","      <td>0.9695</td>\n","      <td>0.9695</td>\n","      <td>524.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score   support\n","2                0.9897  0.9697    0.9796  198.0000\n","3                0.9578  0.9578    0.9578  166.0000\n","5                0.9573  0.9812    0.9691  160.0000\n","accuracy         0.9695  0.9695    0.9695    0.9695\n","macro avg        0.9683  0.9696    0.9689  524.0000\n","weighted avg     0.9697  0.9695    0.9695  524.0000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>192</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>159</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>157</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  192    4    2\n","3    2  159    5\n","5    0    3  157"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Train results:\n","Classification report:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>731.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>658.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>556.0</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1945.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision  recall  f1-score  support\n","2                   1.0     1.0       1.0    731.0\n","3                   1.0     1.0       1.0    658.0\n","5                   1.0     1.0       1.0    556.0\n","accuracy            1.0     1.0       1.0      1.0\n","macro avg           1.0     1.0       1.0   1945.0\n","weighted avg        1.0     1.0       1.0   1945.0"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Confusion matrix:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>731</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>658</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>556</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2    3    5\n","2  731    0    0\n","3    0  658    0\n","5    0    0  556"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"B-7i3730a6xi"},"source":["X_train_decode = X_train_nn.reshape((1945, 256, 1, 1)).astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUGsTsrEcYsu","executionInfo":{"elapsed":835,"status":"ok","timestamp":1613371655755,"user":{"displayName":"Anna Mosenzon","photoUrl":"","userId":"16011365326734362597"},"user_tz":-120},"outputId":"8a8f6993-f822-4d77-b87a-c18a71503599"},"source":["X_train.to_numpy"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method DataFrame.to_numpy of         1      2      3      4      5    ...    252    253    254    255  256\n","1    -1.000 -1.000 -1.000 -0.813 -0.671  ...  0.126 -0.095 -0.671 -0.828 -1.0\n","4    -1.000 -1.000 -1.000 -1.000 -1.000  ...  0.439 -0.199 -0.883 -1.000 -1.0\n","6    -1.000 -1.000 -1.000 -0.830  0.442  ... -1.000 -1.000 -1.000 -1.000 -1.0\n","26   -1.000 -1.000 -1.000 -1.000 -1.000  ...  0.715  0.107 -0.526 -1.000 -1.0\n","30   -1.000 -1.000 -1.000 -1.000 -1.000  ...  0.633 -0.144 -0.994 -1.000 -1.0\n","...     ...    ...    ...    ...    ...  ...    ...    ...    ...    ...  ...\n","7282 -1.000 -0.882 -0.334  0.267  0.333  ...  0.325 -0.820 -1.000 -1.000 -1.0\n","7283 -0.985 -0.048  0.226  0.226  0.226  ... -1.000 -1.000 -1.000 -1.000 -1.0\n","7286 -1.000 -1.000 -1.000 -0.988 -0.527  ... -1.000 -1.000 -1.000 -1.000 -1.0\n","7287 -1.000 -1.000 -1.000 -0.990  0.708  ... -1.000 -1.000 -1.000 -1.000 -1.0\n","7288 -1.000 -1.000 -1.000 -0.783 -0.984  ... -0.933 -1.000 -1.000 -1.000 -1.0\n","\n","[1945 rows x 256 columns]>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUCdM1QrbHpZ","executionInfo":{"elapsed":907,"status":"ok","timestamp":1613371838269,"user":{"displayName":"Anna Mosenzon","photoUrl":"","userId":"16011365326734362597"},"user_tz":-120},"outputId":"e473ecae-0172-4c39-dbae-fd1c444056e4"},"source":["y_train_classes = y_train_nn.argmax(axis = -1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 3, 3, ..., 3, 3, 3])"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"HNGsLbLwcSN8"},"source":[""],"execution_count":null,"outputs":[]}]}